# Phase 13.4: æ™ºèƒ½è¿ç»´å®æ–½æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•æ„å»ºä¼ä¸šçº§æ™ºèƒ½è¿ç»´ï¼ˆAIOpsï¼‰å¹³å°ï¼Œé€šè¿‡AIæŠ€æœ¯å®ç°æ—¥å¿—åˆ†æã€å¼‚å¸¸æ£€æµ‹ã€æ•…éšœé¢„æµ‹ã€è‡ªåŠ¨åŒ–è¿ç»´ç­‰åŠŸèƒ½ï¼Œæå‡è¿ç»´æ•ˆç‡ï¼Œé™ä½ç³»ç»Ÿæ•…éšœç‡ï¼Œå®ç°æ— äººå€¼å®ˆçš„æ™ºèƒ½è¿ç»´ã€‚

---

## ğŸ—ï¸ æ™ºèƒ½è¿ç»´æ•´ä½“æ¶æ„

### æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AIOps æ™ºèƒ½è¿ç»´æ¶æ„                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   å¼‚å¸¸æ£€æµ‹    â”‚  â”‚   æ—¥å¿—åˆ†æ    â”‚  â”‚   æ•…éšœé¢„æµ‹    â”‚           â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚           â”‚
â”‚  â”‚ â€¢ å®æ—¶ç›‘æ§     â”‚  â”‚ â€¢ ELK Stack  â”‚  â”‚ â€¢ æœºå™¨å­¦ä¹      â”‚           â”‚
â”‚  â”‚ â€¢ æ™ºèƒ½å‘Šè­¦     â”‚  â”‚ â€¢ æ—¥å¿—åˆ†ç±»     â”‚  â”‚ â€¢ é¢„æµ‹æ¨¡å‹     â”‚           â”‚
â”‚  â”‚ â€¢ æ ¹å› åˆ†æ     â”‚  â”‚ â€¢ å¼‚å¸¸æ£€æµ‹     â”‚  â”‚ â€¢ è¶‹åŠ¿åˆ†æ     â”‚           â”‚
â”‚  â”‚ â€¢ å…³è”åˆ†æ     â”‚  â”‚ â€¢ æœç´¢èšåˆ     â”‚  â”‚ â€¢ å®¹é‡è§„åˆ’     â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚         â”‚                 â”‚                 â”‚                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   è‡ªåŠ¨åŒ–è¿ç»´    â”‚  â”‚   æ€§èƒ½ä¼˜åŒ–    â”‚  â”‚   çŸ¥è¯†å›¾è°±    â”‚           â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚           â”‚
â”‚  â”‚ â€¢ è‡ªåŠ¨å·¡æ£€     â”‚  â”‚ â€¢ APMç›‘æ§     â”‚  â”‚ â€¢ è¿ç»´çŸ¥è¯†     â”‚           â”‚
â”‚  â”‚ â€¢ è‡ªåŠ¨ä¿®å¤     â”‚  â”‚ â€¢ æ€§èƒ½åˆ†æ     â”‚  â”‚ â€¢ æ•…éšœæ¡ˆä¾‹     â”‚           â”‚
â”‚  â”‚ â€¢ è‡ªåŠ¨éƒ¨ç½²     â”‚  â”‚ â€¢ æ…¢æŸ¥è¯¢åˆ†æ   â”‚  â”‚ â€¢ è§£å†³æ–¹æ¡ˆ     â”‚           â”‚
â”‚  â”‚ â€¢ è‡ªåŠ¨æ‰©ç¼©å®¹   â”‚  â”‚ â€¢ èµ„æºä¼˜åŒ–     â”‚  â”‚ â€¢ æœ€ä½³å®è·µ     â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚         â”‚                 â”‚                 â”‚                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   å®‰å…¨å®¡è®¡     â”‚  â”‚   å®¹é‡ç®¡ç†    â”‚  â”‚   æˆæœ¬ä¼˜åŒ–    â”‚           â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚           â”‚
â”‚  â”‚ â€¢ å®‰å…¨æ—¥å¿—     â”‚  â”‚ â€¢ èµ„æºç›‘æ§     â”‚  â”‚ â€¢ æˆæœ¬åˆ†æ     â”‚           â”‚
â”‚  â”‚ â€¢ å¼‚å¸¸æ£€æµ‹     â”‚  â”‚ â€¢ å®¹é‡é¢„æµ‹     â”‚  â”‚ â€¢ æˆæœ¬ä¼˜åŒ–     â”‚           â”‚
â”‚  â”‚ â€¢ å¨èƒæƒ…æŠ¥     â”‚  â”‚ â€¢ åŠ¨æ€æ‰©å±•     â”‚  â”‚ â€¢ èµ„æºåˆ©ç”¨ç‡   â”‚           â”‚
â”‚  â”‚ â€¢ åˆè§„å®¡è®¡     â”‚  â”‚ â€¢ å®¹é‡è§„åˆ’     â”‚  â”‚ â€¢ è´¹ç”¨é¢„è­¦     â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    æ•°æ®é‡‡é›†å±‚                                 â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ â€¢ Metrics (Prometheus)                                       â”‚ â”‚
â”‚  â”‚ â€¢ Logs (Filebeat/Fluentd)                                   â”‚ â”‚
â”‚  â”‚ â€¢ Traces (Jaeger/Zipkin)                                    â”‚ â”‚
â”‚  â”‚ â€¢ Events (Kubernetes Events)                                â”‚ â”‚
â”‚  â”‚ â€¢ Security Logs (Audit Logs)                                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    å­˜å‚¨åˆ†æå±‚                                 â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ â€¢ Time Series DB (Prometheus/TimescaleDB)                   â”‚ â”‚
â”‚  â”‚ â€¢ Log Storage (Elasticsearch)                               â”‚ â”‚
â”‚  â”‚ â€¢ Trace Storage (Jaeger)                                    â”‚ â”‚
â”‚  â”‚ â€¢ Alert Store (CrateDB)                                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    AIè®¡ç®—å±‚                                   â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ â€¢ TensorFlow (æœºå™¨å­¦ä¹ )                                       â”‚ â”‚
â”‚  â”‚ â€¢ PyTorch (æ·±åº¦å­¦ä¹ )                                          â”‚ â”‚
â”‚  â”‚ â€¢ scikit-learn (ç®—æ³•åº“)                                       â”‚ â”‚
â”‚  â”‚ â€¢ Apache Spark (å¤§æ•°æ®è®¡ç®—)                                   â”‚ â”‚
â”‚  â”‚ â€¢ Apache Flink (æµå¼è®¡ç®—)                                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æŠ€æœ¯æ ˆé€‰å‹

| å±‚æ¬¡ | æŠ€æœ¯ç»„ä»¶ | ç‰ˆæœ¬ | ç”¨é€” |
|------|----------|------|------|
| **æ•°æ®é‡‡é›†** | Promtail | 0.35.0 | æ—¥å¿—æ”¶é›† |
| **æ—¥å¿—å­˜å‚¨** | Elasticsearch | 8.11.0 | æ—¥å¿—å­˜å‚¨æ£€ç´¢ |
| **æ—¶åºæ•°æ®åº“** | Prometheus | 2.47.0 | æŒ‡æ ‡å­˜å‚¨ |
| **æ—¥å¿—å¯è§†åŒ–** | Kibana | 8.11.0 | æ—¥å¿—åˆ†æ |
| **æŒ‡æ ‡å¯è§†åŒ–** | Grafana | 10.2.0 | æŒ‡æ ‡å±•ç¤º |
| **é“¾è·¯è¿½è¸ª** | Jaeger | 1.51.0 | é“¾è·¯è¿½è¸ª |
| **å‘Šè­¦ç®¡ç†** | Alertmanager | 0.26.0 | å‘Šè­¦ç®¡ç† |
| **æœºå™¨å­¦ä¹ ** | TensorFlow | 2.14.0 | å¼‚å¸¸æ£€æµ‹ |
| **å¼‚å¸¸æ£€æµ‹** | PyTorch | 2.1.0 | æ™ºèƒ½åˆ†æ |
| **AIè¿ç»´** | Apache Spark | 3.5.0 | å¤§æ•°æ®å¤„ç† |
| **çŸ¥è¯†å›¾è°±** | Neo4j | 5.15.0 | è¿ç»´çŸ¥è¯† |
| **è‡ªåŠ¨åŒ–** | Ansible | 8.5.0 | è‡ªåŠ¨åŒ–è¿ç»´ |

---

## ğŸ“Š æ•°æ®é‡‡é›†ä¸ç›‘æ§

### 1. Prometheus æŒ‡æ ‡é‡‡é›†

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

# å‘Šè­¦è§„åˆ™æ–‡ä»¶
rule_files:
  - "alert_rules.yml"
  - "recording_rules.yml"

# å‘Šè­¦ç®¡ç†å™¨é…ç½®
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

# é‡‡é›†é…ç½®
scrape_configs:
  # Prometheusè‡ªç›‘æ§
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Spring Bootåº”ç”¨ç›‘æ§
  - job_name: 'spring-boot-apps'
    metrics_path: '/actuator/prometheus'
    scrape_interval: 15s
    static_configs:
      - targets:
          - 'user-service:8080'
          - 'order-service:8080'
          - 'payment-service:8080'
          - 'product-service:8080'

  # æ•°æ®åº“ç›‘æ§
  - job_name: 'mysql-exporter'
    static_configs:
      - targets: ['mysql-exporter:9104']

  - job_name: 'redis-exporter'
    static_configs:
      - targets: ['redis-exporter:9121']

  - job_name: 'elasticsearch-exporter'
    static_configs:
      - targets: ['elasticsearch-exporter:9114']

  # Kubernetesé›†ç¾¤ç›‘æ§
  - job_name: 'kubernetes-nodes'
    kubernetes_sd_configs:
      - role: node
    relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: kubernetes.default.svc:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics

  # å®¹å™¨ç›‘æ§
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name

  # Node Exporter
  - job_name: 'node-exporter'
    kubernetes_sd_configs:
      - role: node
    relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: node-exporter:9100
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: kubernetes_node
```

### 2. æ—¥å¿—é‡‡é›†é…ç½®

```yaml
# filebeat.yml
filebeat.inputs:
- type: container
  paths:
    - /var/log/containers/*-*.log
  processors:
  - add_kubernetes_metadata:
      host: ${NODE_NAME}
      matchers:
      - logs_path:
          logs_path: "/var/log/containers/"

  # è§£æJSONæ—¥å¿—
  - decode_json_fields:
      fields: ["message"]
      target: "json"
      overwrite_keys: true

  # æ·»åŠ å­—æ®µ
  - add_fields:
      fields:
        service: "aiops"
        environment: "production"

  # è¿‡æ»¤æ—¥å¿—çº§åˆ«
  - include_fields:
      fields: ["log.level", "message", "service", "json.level"]

output.logstash:
  hosts: ["logstash:5044"]

# å¤„ç†æ—¥å¿—æ ¼å¼
filter {
  if [fields][service] == "aiops" {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{DATA:logger} %{GREEDYDATA:message}"
      }
    }

    date {
      match => [ "timestamp", "yyyy-MM-dd HH:mm:ss.SSS" ]
    }

    mutate {
      remove_field => [ "host", "agent", "input", "ecs", "@version" ]
    }
  }
}
```

### 3. é“¾è·¯è¿½è¸ªé…ç½®

```yaml
# jaeger-operatoré…ç½®
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: basebackend-jaeger
spec:
  strategy: production
  storage:
    type: elasticsearch
    options:
      es:
        server-urls: http://elasticsearch:9200
        username: elastic
        password: changeme
  collector:
    maxReplicas: 3
    resources:
      limits:
        cpu: 1
        memory: 1Gi
      requests:
        cpu: 500m
        memory: 512Mi
  query:
    replicas: 2
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 250m
        memory: 256Mi
```

---

## ğŸ” å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ

### 1. å¼‚å¸¸æ£€æµ‹ç®—æ³•

```java
/**
 * å¼‚å¸¸æ£€æµ‹æœåŠ¡
 * ä½¿ç”¨å¤šç§ç®—æ³•è¿›è¡Œå¼‚å¸¸æ£€æµ‹
 */
@Service
public class AnomalyDetectionService {

    @Autowired
    private PrometheusService prometheusService;

    @Autowired
    private ElasticSearchService elasticSearchService;

    @Autowired
    private MachineLearningService mlService;

    /**
     * åŸºäºç»Ÿè®¡å­¦çš„å¼‚å¸¸æ£€æµ‹
     */
    public List<AnomalyAlert> detectStatisticalAnomaly(String metric, Duration window) {
        // è·å–æ—¶é—´åºåˆ—æ•°æ®
        List<TimeSeriesData> timeSeries = prometheusService.queryRange(
            metric,
            Instant.now().minus(window),
            Instant.now(),
            Duration.ofMinutes(1)
        );

        // è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        StatisticalSummary summary = calculateStatistics(timeSeries);

        // 3-sigmaè§„åˆ™æ£€æµ‹
        List<AnomalyAlert> anomalies = new ArrayList<>();
        for (TimeSeriesData point : timeSeries) {
            double zScore = Math.abs((point.getValue() - summary.getMean()) / summary.getStdDev());

            if (zScore > 3) {
                AnomalyAlert alert = AnomalyAlert.builder()
                    .metric(metric)
                    .timestamp(point.getTimestamp())
                    .value(point.getValue())
                    .zScore(zScore)
                    .severity(Severity.HIGH)
                    .type(AnomalyType.STATISTICAL)
                    .description("æ£€æµ‹åˆ°ç»Ÿè®¡å­¦å¼‚å¸¸ï¼Œz-score: " + zScore)
                    .build();

                anomalies.add(alert);
            }
        }

        return anomalies;
    }

    /**
     * åŸºäºæœºå™¨å­¦ä¹ çš„å¼‚å¸¸æ£€æµ‹
     */
    public List<AnomalyAlert> detectMLAnomaly(String metric, Duration window) {
        // è·å–æ—¶é—´åºåˆ—æ•°æ®
        List<TimeSeriesData> timeSeries = prometheusService.queryRange(
            metric,
            Instant.now().minus(window.multipliedBy(2)), // è·å–æ›´é•¿æ—¶é—´çª—å£ç”¨äºè®­ç»ƒ
            Instant.now(),
            Duration.ofMinutes(1)
        );

        // ä½¿ç”¨LSTMæ¨¡å‹æ£€æµ‹å¼‚å¸¸
        List<AnomalyAlert> anomalies = mlService.detectAnomaliesWithLSTM(timeSeries);

        // ä½¿ç”¨Isolation Forestæ£€æµ‹å¼‚å¸¸
        anomalies.addAll(mlService.detectAnomaliesWithIsolationForest(timeSeries));

        // ä½¿ç”¨One-Class SVMæ£€æµ‹å¼‚å¸¸
        anomalies.addAll(mlService.detectAnomaliesWithOCSVM(timeSeries));

        return anomalies;
    }

    /**
     * åŸºäºæ—¥å¿—çš„å¼‚å¸¸æ£€æµ‹
     */
    public List<AnomalyAlert> detectLogAnomaly(String service, Duration window) {
        // æŸ¥è¯¢æ—¥å¿—
        SearchRequest searchRequest = new SearchRequest("logs-*")
            .source(SearchSourceBuilder.searchSource()
                .query(QueryBuilders.boolQuery()
                    .must(QueryBuilders.termQuery("service", service))
                    .must(QueryBuilders.rangeQuery("@timestamp")
                        .gte(Instant.now().minus(window).toEpochMilli())))
                .size(1000));

        try {
            SearchResponse response = elasticSearchService.search(searchRequest);
            List<String> logs = parseLogs(response);

            // ä½¿ç”¨NLPåˆ†ææ—¥å¿—
            List<LogAnomaly> logAnomalies = analyzeLogsWithNLP(logs);

            // è½¬æ¢ä¸ºå‘Šè­¦
            return logAnomalies.stream()
                .map(anomaly -> AnomalyAlert.builder()
                    .metric("log_error_rate")
                    .timestamp(anomaly.getTimestamp())
                    .value(1.0)
                    .severity(Severity.MEDIUM)
                    .type(AnomalyType.LOG_ANOMALY)
                    .description("æ£€æµ‹åˆ°å¼‚å¸¸æ—¥å¿—: " + anomaly.getDescription())
                    .build())
                .collect(Collectors.toList());

        } catch (Exception e) {
            log.error("æ—¥å¿—å¼‚å¸¸æ£€æµ‹å¤±è´¥", e);
            return Collections.emptyList();
        }
    }

    /**
     * åŸºäºå…³è”è§„åˆ™çš„å¼‚å¸¸æ£€æµ‹
     */
    public List<AnomalyAlert> detectCorrelationAnomaly(String metric, Duration window) {
        // è·å–ç›¸å…³æŒ‡æ ‡
        List<String> relatedMetrics = findRelatedMetrics(metric);

        List<TimeSeriesData>[] timeSeriesData = new List[relatedMetrics.size() + 1];
        timeSeriesData[0] = prometheusService.queryRange(
            metric,
            Instant.now().minus(window),
            Instant.now(),
            Duration.ofMinutes(1)
        );

        for (int i = 0; i < relatedMetrics.size(); i++) {
            timeSeriesData[i + 1] = prometheusService.queryRange(
                relatedMetrics.get(i),
                Instant.now().minus(window),
                Instant.now(),
                Duration.ofMinutes(1)
            );
        }

        // è®¡ç®—ç›¸å…³æ€§
        double correlation = calculateCorrelation(timeSeriesData[0], timeSeriesData[1]);

        // å¦‚æœç›¸å…³æ€§çªç„¶å˜åŒ–ï¼Œå¯èƒ½å­˜åœ¨å¼‚å¸¸
        List<AnomalyAlert> anomalies = new ArrayList<>();

        if (Math.abs(correlation) < 0.3) { // ç›¸å…³æ€§è¿‡ä½
            AnomalyAlert alert = AnomalyAlert.builder()
                .metric(metric)
                .timestamp(Instant.now())
                .value(correlation)
                .severity(Severity.MEDIUM)
                .type(AnomalyType.CORRELATION_ANOMALY)
                .description("æ£€æµ‹åˆ°ç›¸å…³æ€§å¼‚å¸¸ï¼Œä¸" + relatedMetrics.get(0) + "çš„ç›¸å…³æ€§: " + correlation)
                .build();

            anomalies.add(alert);
        }

        return anomalies;
    }

    /**
     * ç»„åˆå¤šç§æ–¹æ³•è¿›è¡Œå¼‚å¸¸æ£€æµ‹
     */
    public List<AnomalyAlert> detectComprehensiveAnomaly(String metric, Duration window) {
        List<AnomalyAlert> allAnomalies = new ArrayList<>();

        // ç»Ÿè®¡å­¦æ–¹æ³•
        allAnomalies.addAll(detectStatisticalAnomaly(metric, window));

        // æœºå™¨å­¦ä¹ æ–¹æ³•
        allAnomalies.addAll(detectMLAnomaly(metric, window));

        // æ—¥å¿—åˆ†æ
        allAnomalies.addAll(detectLogAnomaly(metric, window));

        // å…³è”åˆ†æ
        allAnomalies.addAll(detectCorrelationAnomaly(metric, window));

        // å»é™¤é‡å¤å‘Šè­¦
        return removeDuplicateAlerts(allAnomalies);
    }

    private StatisticalSummary calculateStatistics(List<TimeSeriesData> timeSeries) {
        if (timeSeries.isEmpty()) {
            return StatisticalSummary.builder().build();
        }

        double sum = timeSeries.stream().mapToDouble(TimeSeriesData::getValue).sum();
        double mean = sum / timeSeries.size();

        double variance = timeSeries.stream()
            .mapToDouble(point -> Math.pow(point.getValue() - mean, 2))
            .sum() / timeSeries.size();

        double stdDev = Math.sqrt(variance);

        double min = timeSeries.stream().mapToDouble(TimeSeriesData::getValue).min().orElse(0);
        double max = timeSeries.stream().mapToDouble(TimeSeriesData::getValue).max().orElse(0);

        return StatisticalSummary.builder()
            .mean(mean)
            .stdDev(stdDev)
            .variance(variance)
            .min(min)
            .max(max)
            .count(timeSeries.size())
            .build();
    }

    private double calculateCorrelation(List<TimeSeriesData> series1, List<TimeSeriesData> series2) {
        if (series1.size() != series2.size() || series1.isEmpty()) {
            return 0;
        }

        double sum1 = series1.stream().mapToDouble(TimeSeriesData::getValue).sum();
        double sum2 = series2.stream().mapToDouble(TimeSeriesData::getValue).sum();
        double sum1Sq = series1.stream().mapToDouble(p -> Math.pow(p.getValue(), 2)).sum();
        double sum2Sq = series2.stream().mapToDouble(p -> Math.pow(p.getValue(), 2)).sum();

        double pSum = 0;
        for (int i = 0; i < series1.size(); i++) {
            pSum += series1.get(i).getValue() * series2.get(i).getValue();
        }

        double num = pSum - (sum1 * sum2 / series1.size());
        double den = Math.sqrt((sum1Sq - sum1 * sum1 / series1.size()) *
                (sum2Sq - sum2 * sum2 / series1.size()));

        return den == 0 ? 0 : num / den;
    }

    private List<String> findRelatedMetrics(String metric) {
        // æŸ¥æ‰¾ç›¸å…³çš„æŒ‡æ ‡
        List<String> relatedMetrics = new ArrayList<>();

        if (metric.contains("cpu")) {
            relatedMetrics.add("memory_usage");
            relatedMetrics.add("network_io");
        } else if (metric.contains("memory")) {
            relatedMetrics.add("cpu_usage");
            relatedMetrics.add("disk_io");
        }

        return relatedMetrics;
    }

    private List<AnomalyAlert> removeDuplicateAlerts(List<AnomalyAlert> anomalies) {
        // æŒ‰æ—¶é—´çª—å£å»é‡
        Map<String, AnomalyAlert> alertMap = new LinkedHashMap<>();

        for (AnomalyAlert alert : anomalies) {
            String key = alert.getMetric() + "_" +
                    alert.getType() + "_" +
                    alert.getTimestamp().truncatedTo(ChronoUnit.MINUTES);

            alertMap.put(key, alert);
        }

        return new ArrayList<>(alertMap.values());
    }
}

/**
 * æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹æœåŠ¡
 */
@Service
public class MachineLearningService {

    /**
     * ä½¿ç”¨LSTMæ£€æµ‹å¼‚å¸¸
     */
    public List<AnomalyAlert> detectAnomaliesWithLSTM(List<TimeSeriesData> timeSeries) {
        // æ„å»ºLSTMæ¨¡å‹
        Sequential model = new Sequential();
        model.add(new LSTM(50, returnSequences = true, inputShape = new int[]{60, 1}));
        model.add(new LSTM(50, returnSequences = true));
        model.add(new LSTM(50));
        model.add(new Dense(1));
        model.compile(optimizer = Adam, loss = "mse");

        // è®­ç»ƒæ¨¡å‹
        INDArray features = NDArrayUtils.convertToINDArray(timeSeries);
        INDArray target = NDArrayUtils.convertToINDArray(timeSeries);

        model.fit(features, target, epochs = 50, batchSize = 32, verbose = 0);

        // é¢„æµ‹å¹¶æ£€æµ‹å¼‚å¸¸
        INDArray predictions = model.predict(features);
        List<AnomalyAlert> anomalies = new ArrayList<>();

        for (int i = 0; i < timeSeries.size(); i++) {
            double actual = timeSeries.get(i).getValue();
            double predicted = predictions.getDouble(i);

            double error = Math.abs(actual - predicted);
            double threshold = calculateThreshold(predictions);

            if (error > threshold) {
                AnomalyAlert alert = AnomalyAlert.builder()
                    .metric("lstm_anomaly")
                    .timestamp(timeSeries.get(i).getTimestamp())
                    .value(actual)
                    .severity(Severity.HIGH)
                    .type(AnomalyType.ML_ANOMALY)
                    .description("LSTMæ£€æµ‹åˆ°å¼‚å¸¸ï¼Œé¢„æµ‹è¯¯å·®: " + error)
                    .build();

                anomalies.add(alert);
            }
        }

        return anomalies;
    }

    /**
     * ä½¿ç”¨Isolation Forestæ£€æµ‹å¼‚å¸¸
     */
    public List<AnomalyAlert> detectAnomaliesWithIsolationForest(List<TimeSeriesData> timeSeries) {
        // ç‰¹å¾æå–
        double[][] features = extractFeatures(timeSeries);

        // è®­ç»ƒIsolation Forest
        IsolationForest model = new IsolationForest();
        model.fit(features);

        // æ£€æµ‹å¼‚å¸¸
        List<AnomalyAlert> anomalies = new ArrayList<>();

        for (int i = 0; i < timeSeries.size(); i++) {
            double anomalyScore = model.predict(features[i]);

            if (anomalyScore > 0.6) { // é˜ˆå€¼å¯è°ƒ
                AnomalyAlert alert = AnomalyAlert.builder()
                    .metric("isolation_forest_anomaly")
                    .timestamp(timeSeries.get(i).getTimestamp())
                    .value(timeSeries.get(i).getValue())
                    .severity(Severity.MEDIUM)
                    .type(AnomalyType.ML_ANOMALY)
                    .description("Isolation Forestæ£€æµ‹åˆ°å¼‚å¸¸ï¼Œåˆ†æ•°: " + anomalyScore)
                    .build();

                anomalies.add(alert);
            }
        }

        return anomalies;
    }

    /**
     * ä½¿ç”¨One-Class SVMæ£€æµ‹å¼‚å¸¸
     */
    public List<AnomalyAlert> detectAnomaliesWithOCSVM(List<TimeSeriesData> timeSeries) {
        double[][] features = extractFeatures(timeSeries);

        OneClassSVM model = new OneClassSVM();
        model.fit(features);

        List<AnomalyAlert> anomalies = new ArrayList<>();

        for (int i = 0; i < timeSeries.size(); i++) {
            int prediction = model.predict(features[i]);

            if (prediction == -1) { // -1è¡¨ç¤ºå¼‚å¸¸
                AnomalyAlert alert = AnomalyAlert.builder()
                    .metric("ocsvm_anomaly")
                    .timestamp(timeSeries.get(i).getTimestamp())
                    .value(timeSeries.get(i).getValue())
                    .severity(Severity.MEDIUM)
                    .type(AnomalyType.ML_ANOMALY)
                    .description("One-Class SVMæ£€æµ‹åˆ°å¼‚å¸¸")
                    .build();

                anomalies.add(alert);
            }
        }

        return anomalies;
    }

    private double[][] extractFeatures(List<TimeSeriesData> timeSeries) {
        double[][] features = new double[timeSeries.size()][10];

        for (int i = 0; i < timeSeries.size(); i++) {
            TimeSeriesData data = timeSeries.get(i);

            // æå–ç»Ÿè®¡ç‰¹å¾
            double value = data.getValue();

            features[i][0] = value;
            features[i][1] = Math.log(Math.max(value, 0.1)); // å¯¹æ•°å˜æ¢
            features[i][2] = Math.sqrt(Math.max(value, 0)); // å¹³æ–¹æ ¹å˜æ¢

            // æ»‘åŠ¨å¹³å‡
            if (i > 0) {
                features[i][3] = (timeSeries.get(i - 1).getValue() + value) / 2;
            }

            // å˜åŒ–ç‡
            if (i > 0) {
                double prevValue = timeSeries.get(i - 1).getValue();
                features[i][4] = prevValue != 0 ? (value - prevValue) / prevValue : 0;
            }

            // æ—¶é—´ç‰¹å¾
            LocalDateTime timestamp = LocalDateTime.ofInstant(data.getTimestamp(), ZoneOffset.UTC);
            features[i][5] = timestamp.getHour();
            features[i][6] = timestamp.getDayOfWeek().getValue();
            features[i][7] = timestamp.getMonthValue();

            // ç´¯ç§¯ç‰¹å¾
            features[i][8] = timeSeries.stream()
                .limit(i + 1)
                .mapToDouble(TimeSeriesData::getValue)
                .average()
                .orElse(0);

            features[i][9] = timeSeries.stream()
                .limit(i + 1)
                .mapToDouble(TimeSeriesData::getValue)
                .max()
                .orElse(0);
        }

        return features;
    }

    private double calculateThreshold(INDArray predictions) {
        double[] values = new double[(int) predictions.size()];
        for (int i = 0; i < values.length; i++) {
            values[i] = predictions.getDouble(i);
        }

        double mean = Arrays.stream(values).average().orElse(0);
        double stdDev = Math.sqrt(
            Arrays.stream(values)
                .map(x -> Math.pow(x - mean, 2))
                .average()
                .orElse(0)
        );

        return mean + 3 * stdDev; // 3-sigmaé˜ˆå€¼
    }
}
```

### 2. æ ¹å› åˆ†æç³»ç»Ÿ

```java
/**
 * æ ¹å› åˆ†ææœåŠ¡
 */
@Service
public class RootCauseAnalysisService {

    @Autowired
    private PrometheusService prometheusService;

    @Autowired
    private ElasticSearchService elasticSearchService;

    @Autowired
    private JaegerService jaegerService;

    /**
     * è‡ªåŠ¨åŒ–æ ¹å› åˆ†æ
     */
    public RootCauseAnalysisResult analyzeRootCause(AnomalyAlert alert) {
        RootCauseAnalysisResult.Builder builder = RootCauseAnalysisResult.builder()
            .alert(alert)
            .startTime(Instant.now())
            .analysisTime(windowStart(alert.getTimestamp()));

        try {
            // 1. æ”¶é›†ç›¸å…³æ•°æ®
            RelatedData relatedData = collectRelatedData(alert);

            // 2. æŒ‡æ ‡å…³è”åˆ†æ
            MetricCorrelation correlation = analyzeMetricCorrelation(alert, relatedData);

            // 3. æ—¥å¿—å¼‚å¸¸åˆ†æ
            List<LogAnomaly> logAnomalies = analyzeLogAnomalies(alert, relatedData);

            // 4. è°ƒç”¨é“¾åˆ†æ
            List<TraceAnomaly> traceAnomalies = analyzeTraceAnomalies(alert, relatedData);

            // 5. é…ç½®å˜æ›´åˆ†æ
            List<ConfigChange> configChanges = analyzeConfigChanges(alert, relatedData);

            // 6. èµ„æºä½¿ç”¨åˆ†æ
            List<ResourceAnomaly> resourceAnomalies = analyzeResourceUsage(alert, relatedData);

            // 7. ä¾èµ–æœåŠ¡åˆ†æ
            List<ServiceAnomaly> serviceAnomalies = analyzeDependencyServices(alert, relatedData);

            // 8. ç»¼åˆåˆ†æ
            List<RootCause> possibleCauses = analyzePossibleCauses(
                correlation, logAnomalies, traceAnomalies,
                configChanges, resourceAnomalies, serviceAnomalies
            );

            builder.relatedData(relatedData)
                .metricCorrelation(correlation)
                .logAnomalies(logAnomalies)
                .traceAnomalies(traceAnomalies)
                .configChanges(configChanges)
                .resourceAnomalies(resourceAnomalies)
                .serviceAnomalies(serviceAnomalies)
                .possibleCauses(possibleCauses)
                .confidence(calculateConfidence(possibleCauses));

        } catch (Exception e) {
            log.error("æ ¹å› åˆ†æå¤±è´¥", e);
            builder.error(e.getMessage());
        }

        return builder.endTime(Instant.now()).build();
    }

    /**
     * æ”¶é›†ç›¸å…³æ•°æ®
     */
    private RelatedData collectRelatedData(AnomalyAlert alert) {
        Instant windowStart = windowStart(alert.getTimestamp());
        Instant windowEnd = alert.getTimestamp().plus(Duration.ofMinutes(30));

        RelatedData.Builder builder = RelatedData.builder();

        // æ”¶é›†ç›¸å…³æŒ‡æ ‡
        List<TimeSeriesData> relatedMetrics = prometheusService.queryRelatedMetrics(
            alert.getMetric(),
            windowStart,
            windowEnd
        );
        builder.relatedMetrics(relatedMetrics);

        // æ”¶é›†æ—¥å¿—
        List<String> logs = elasticSearchService.queryLogs(
            alert.getMetric(),
            windowStart,
            windowEnd
        );
        builder.logs(logs);

        // æ”¶é›†é“¾è·¯è¿½è¸ª
        List<Span> traces = jaegerService.queryTraces(
            alert.getMetric(),
            windowStart,
            windowEnd
        );
        builder.traces(traces);

        return builder.build();
    }

    /**
     * æŒ‡æ ‡å…³è”åˆ†æ
     */
    private MetricCorrelation analyzeMetricCorrelation(AnomalyAlert alert, RelatedData data) {
        Map<String, Double> correlations = new HashMap<>();

        for (TimeSeriesData metric : data.getRelatedMetrics()) {
            if (!metric.getMetricName().equals(alert.getMetric())) {
                double correlation = calculateCorrelation(
                    Collections.singletonList(alert.getMetric()),
                    Collections.singletonList(metric.getMetricName())
                );
                correlations.put(metric.getMetricName(), correlation);
            }
        }

        // æ‰¾å‡ºç›¸å…³æ€§æœ€é«˜çš„æŒ‡æ ‡
        String mostCorrelatedMetric = correlations.entrySet().stream()
            .max(Map.Entry.comparingByValue())
            .map(Map.Entry::getKey)
            .orElse(null);

        return MetricCorrelation.builder()
            .correlations(correlations)
            .mostCorrelatedMetric(mostCorrelatedMetric)
            .build();
    }

    /**
     * æ—¥å¿—å¼‚å¸¸åˆ†æ
     */
    private List<LogAnomaly> analyzeLogAnomalies(AnomalyAlert alert, RelatedData data) {
        List<LogAnomaly> anomalies = new ArrayList<>();

        // ä½¿ç”¨NLPåˆ†ææ—¥å¿—å¼‚å¸¸
        for (String log : data.getLogs()) {
            if (isAnomalousLog(log)) {
                LogAnomaly anomaly = LogAnomaly.builder()
                    .log(log)
                    .reason(analyzeLogReason(log))
                    .severity(calculateLogSeverity(log))
                    .build();

                anomalies.add(anomaly);
            }
        }

        return anomalies;
    }

    /**
     * è°ƒç”¨é“¾åˆ†æ
     */
    private List<TraceAnomaly> analyzeTraceAnomalies(AnomalyAlert alert, RelatedData data) {
        List<TraceAnomaly> anomalies = new ArrayList<>();

        for (Span span : data.getTraces()) {
            // æ£€æŸ¥å“åº”æ—¶é—´å¼‚å¸¸
            if (span.getDuration() > getThreshold(span.getOperationName())) {
                TraceAnomaly anomaly = TraceAnomaly.builder()
                    .spanId(span.getSpanId())
                    .operationName(span.getOperationName())
                    .duration(span.getDuration())
                    .reason("å“åº”æ—¶é—´å¼‚å¸¸")
                    .severity(Severity.HIGH)
                    .build();

                anomalies.add(anomaly);
            }

            // æ£€æŸ¥é”™è¯¯ç‡å¼‚å¸¸
            if (span.isError()) {
                TraceAnomaly anomaly = TraceAnomaly.builder()
                    .spanId(span.getSpanId())
                    .operationName(span.getOperationName())
                    .reason("æœåŠ¡è°ƒç”¨å¤±è´¥")
                    .severity(Severity.CRITICAL)
                    .errorMessage(span.getErrorMessage())
                    .build();

                anomalies.add(anomaly);
            }
        }

        return anomalies;
    }

    /**
     * é…ç½®å˜æ›´åˆ†æ
     */
    private List<ConfigChange> analyzeConfigChanges(AnomalyAlert alert, RelatedData data) {
        List<ConfigChange> changes = new ArrayList<>();

        // æŸ¥è¯¢é…ç½®å˜æ›´å†å²
        List<ConfigChange> configChanges = ConfigChangeHistory.query(
            alert.getTimestamp().minus(Duration.ofHours(1)),
            alert.getTimestamp()
        );

        for (ConfigChange change : configChanges) {
            // æ£€æŸ¥å˜æ›´æ˜¯å¦ä¸å¼‚å¸¸ç›¸å…³
            if (isConfigChangeRelevant(change, alert)) {
                changes.add(change);
            }
        }

        return changes;
    }

    /**
     * èµ„æºä½¿ç”¨åˆ†æ
     */
    private List<ResourceAnomaly> analyzeResourceUsage(AnomalyAlert alert, RelatedData data) {
        List<ResourceAnomaly> anomalies = new ArrayList<>();

        // æ£€æŸ¥CPUä½¿ç”¨ç‡
        Double cpuUsage = findMetricValue(data.getRelatedMetrics(), "cpu_usage");
        if (cpuUsage != null && cpuUsage > 80) {
            anomalies.add(ResourceAnomaly.builder()
                .resourceType("CPU")
                .usage(cpuUsage)
                .threshold(80.0)
                .reason("CPUä½¿ç”¨ç‡è¿‡é«˜")
                .severity(Severity.HIGH)
                .build());
        }

        // æ£€æŸ¥å†…å­˜ä½¿ç”¨ç‡
        Double memoryUsage = findMetricValue(data.getRelatedMetrics(), "memory_usage");
        if (memoryUsage != null && memoryUsage > 85) {
            anomalies.add(ResourceAnomaly.builder()
                .resourceType("Memory")
                .usage(memoryUsage)
                .threshold(85.0)
                .reason("å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜")
                .severity(Severity.HIGH)
                .build());
        }

        // æ£€æŸ¥ç£ç›˜I/O
        Double diskIO = findMetricValue(data.getRelatedMetrics(), "disk_io");
        if (diskIO != null && diskIO > 1000) {
            anomalies.add(ResourceAnomaly.builder()
                .resourceType("Disk")
                .usage(diskIO)
                .threshold(1000.0)
                .reason("ç£ç›˜I/Oè¿‡é«˜")
                .severity(Severity.MEDIUM)
                .build());
        }

        return anomalies;
    }

    /**
     * ä¾èµ–æœåŠ¡åˆ†æ
     */
    private List<ServiceAnomaly> analyzeDependencyServices(AnomalyAlert alert, RelatedData data) {
        List<ServiceAnomaly> anomalies = new ArrayList<>();

        // è·å–æœåŠ¡ä¾èµ–å…³ç³»
        Set<String> dependencies = ServiceDependency.getDependencies(alert.getMetric());

        for (String dependency : dependencies) {
            // æ£€æŸ¥ä¾èµ–æœåŠ¡çš„å¥åº·çŠ¶æ€
            ServiceHealth health = checkServiceHealth(dependency);

            if (health.getStatus() != ServiceStatus.HEALTHY) {
                ServiceAnomaly anomaly = ServiceAnomaly.builder()
                    .serviceName(dependency)
                    .status(health.getStatus())
                    .reason(health.getErrorMessage())
                    .severity(Severity.HIGH)
                    .build();

                anomalies.add(anomaly);
            }

            // æ£€æŸ¥ä¾èµ–æœåŠ¡çš„æŒ‡æ ‡
            Double responseTime = health.getResponseTime();
            if (responseTime != null && responseTime > getThreshold(dependency)) {
                ServiceAnomaly anomaly = ServiceAnomaly.builder()
                    .serviceName(dependency)
                    .status(ServiceStatus.SLOW)
                    .reason("ä¾èµ–æœåŠ¡å“åº”ç¼“æ…¢")
                    .responseTime(responseTime)
                    .severity(Severity.MEDIUM)
                    .build();

                anomalies.add(anomaly);
            }
        }

        return anomalies;
    }

    /**
     * ç»¼åˆåˆ†æå¯èƒ½çš„åŸå› 
     */
    private List<RootCause> analyzePossibleCauses(MetricCorrelation correlation,
                                                  List<LogAnomaly> logAnomalies,
                                                  List<TraceAnomaly> traceAnomalies,
                                                  List<ConfigChange> configChanges,
                                                  List<ResourceAnomaly> resourceAnomalies,
                                                  List<ServiceAnomaly> serviceAnomalies) {
        List<RootCause> causes = new ArrayList<>();

        // é…ç½®å˜æ›´å¯¼è‡´çš„é—®é¢˜
        if (!configChanges.isEmpty()) {
            RootCause cause = RootCause.builder()
                .cause("é…ç½®å˜æ›´")
                .description("æ£€æµ‹åˆ°ç›¸å…³é…ç½®å˜æ›´ï¼Œå¯èƒ½å¯¼è‡´é—®é¢˜")
                .evidence(configChanges)
                .probability(0.8)
                .severity(Severity.HIGH)
                .recommendation("å›æ»šæœ€è¿‘çš„é…ç½®å˜æ›´")
                .build();

            causes.add(cause);
        }

        // èµ„æºä¸è¶³å¯¼è‡´çš„é—®é¢˜
        if (!resourceAnomalies.isEmpty()) {
            RootCause cause = RootCause.builder()
                .cause("èµ„æºä¸è¶³")
                .description("æ£€æµ‹åˆ°èµ„æºä½¿ç”¨ç‡è¿‡é«˜")
                .evidence(resourceAnomalies)
                .probability(0.7)
                .severity(Severity.MEDIUM)
                .recommendation("å¢åŠ èµ„æºé…ç½®æˆ–ä¼˜åŒ–åº”ç”¨æ€§èƒ½")
                .build();

            causes.add(cause);
        }

        // ä¾èµ–æœåŠ¡å¼‚å¸¸
        if (!serviceAnomalies.isEmpty()) {
            RootCause cause = RootCause.builder()
                .cause("ä¾èµ–æœåŠ¡å¼‚å¸¸")
                .description("æ£€æµ‹åˆ°ä¾èµ–æœåŠ¡å¼‚å¸¸")
                .evidence(serviceAnomalies)
                .probability(0.6)
                .severity(Severity.HIGH)
                .recommendation("æ£€æŸ¥ä¾èµ–æœåŠ¡çŠ¶æ€")
                .build();

            causes.add(cause);
        }

        // åº”ç”¨æ—¥å¿—å¼‚å¸¸
        if (!logAnomalies.isEmpty()) {
            RootCause cause = RootCause.builder()
                .cause("åº”ç”¨æ—¥å¿—å¼‚å¸¸")
                .description("æ£€æµ‹åˆ°åº”ç”¨æ—¥å¿—å¼‚å¸¸")
                .evidence(logAnomalies)
                .probability(0.5)
                .severity(Severity.MEDIUM)
                .recommendation("æ£€æŸ¥åº”ç”¨ä»£ç å’Œæ—¥å¿—")
                .build();

            causes.add(cause);
        }

        // è°ƒç”¨é“¾å¼‚å¸¸
        if (!traceAnomalies.isEmpty()) {
            RootCause cause = RootCause.builder()
                .cause("è°ƒç”¨é“¾å¼‚å¸¸")
                .description("æ£€æµ‹åˆ°è°ƒç”¨é“¾å¼‚å¸¸")
                .evidence(traceAnomalies)
                .probability(0.6)
                .severity(Severity.HIGH)
                .recommendation("æ£€æŸ¥æœåŠ¡é—´è°ƒç”¨")
                .build();

            causes.add(cause);
        }

        return causes;
    }

    private Double findMetricValue(List<TimeSeriesData> metrics, String metricName) {
        return metrics.stream()
            .filter(m -> m.getMetricName().equals(metricName))
            .mapToDouble(TimeSeriesData::getValue)
            .findFirst()
            .orElse(0);
    }

    private Instant windowStart(Instant timestamp) {
        return timestamp.minus(Duration.ofMinutes(30));
    }
}
```

---

## ğŸ“ æ—¥å¿—åˆ†æç³»ç»Ÿ

### 1. æ—¥å¿—èšåˆä¸æ£€ç´¢

```java
/**
 * æ—¥å¿—åˆ†ææœåŠ¡
 */
@Service
@Validated
public class LogAnalysisService {

    @Autowired
    private ElasticSearchService elasticSearchService;

    @Autowired
    private NaturalLanguageProcessor nlpService;

    @Autowired
    private MachineLearningService mlService;

    /**
     * æ—¥å¿—æœç´¢
     */
    public LogSearchResult searchLogs(LogSearchRequest request) {
        try {
            // æ„å»ºæŸ¥è¯¢æ¡ä»¶
            BoolQueryBuilder queryBuilder = QueryBuilders.boolQuery();

            // æ—¶é—´èŒƒå›´
            if (request.getStartTime() != null && request.getEndTime() != null) {
                queryBuilder.must(QueryBuilders.rangeQuery("@timestamp")
                    .gte(request.getStartTime().toEpochMilli())
                    .lte(request.getEndTime().toEpochMilli()));
            }

            // æœåŠ¡ç­›é€‰
            if (StringUtils.hasText(request.getService())) {
                queryBuilder.must(QueryBuilders.termQuery("service", request.getService()));
            }

            // æ—¥å¿—çº§åˆ«ç­›é€‰
            if (StringUtils.hasText(request.getLevel())) {
                queryBuilder.must(QueryBuilders.termQuery("level", request.getLevel()));
            }

            // å…³é”®è¯æœç´¢
            if (StringUtils.hasText(request.getKeyword())) {
                queryBuilder.must(QueryBuilders.multiMatchQuery(request.getKeyword())
                    .field("message", 2.0f)
                    .field("exception", 1.5f)
                    .field("stackTrace", 1.0f));
            }

            // æ„å»ºæœç´¢è¯·æ±‚
            SearchSourceBuilder searchSource = new SearchSourceBuilder();
            searchSource.query(queryBuilder);

            // åˆ†é¡µ
            searchSource.from(request.getPage() * request.getSize());
            searchSource.size(request.getSize());

            // æ’åº
            if (StringUtils.hasText(request.getSortField())) {
                searchSource.sort(request.getSortField(),
                    request.getSortOrder() != null ? request.getSortOrder() : SortOrder.DESC);
            } else {
                searchSource.sort("@timestamp", SortOrder.DESC);
            }

            // é«˜äº®æ˜¾ç¤º
            HighlightBuilder highlightBuilder = new HighlightBuilder();
            highlightBuilder.field("message");
            highlightBuilder.field("exception");
            highlightBuilder.preTags("<font color='red'>");
            highlightBuilder.postTags("</font>");
            searchSource.highlighter(highlightBuilder);

            // æ‰§è¡Œæœç´¢
            SearchRequest searchRequest = new SearchRequest("logs-*");
            searchRequest.source(searchSource);

            SearchResponse response = elasticSearchService.search(searchRequest);

            // è§£æç»“æœ
            return parseLogSearchResponse(response);

        } catch (Exception e) {
            log.error("æ—¥å¿—æœç´¢å¤±è´¥", e);
            throw new BusinessException("æ—¥å¿—æœç´¢å¤±è´¥: " + e.getMessage());
        }
    }

    /**
     * æ—¥å¿—åˆ†ç±»
     */
    @Transactional(readOnly = true)
    public List<LogCategory> classifyLogs(LogSearchRequest request) {
        try {
            LogSearchResult searchResult = searchLogs(request);

            // ä½¿ç”¨NLPå¯¹æ—¥å¿—è¿›è¡Œåˆ†ç±»
            List<LogCategory> categories = new ArrayList<>();

            for (LogEntry log : searchResult.getLogs()) {
                LogCategory category = nlpService.classifyLog(log.getMessage());
                categories.add(category);
            }

            // ç»Ÿè®¡åˆ†ç±»ç»“æœ
            Map<LogType, Long> counts = categories.stream()
                .collect(Collectors.groupingBy(
                    LogCategory::getType,
                    Collectors.counting()
                ));

            return counts.entrySet().stream()
                .map(entry -> LogCategory.builder()
                    .type(entry.getKey())
                    .count(entry.getValue())
                    .description(getCategoryDescription(entry.getKey()))
                    .build())
                .sorted(Comparator.comparing(LogCategory::getCount).reversed())
                .collect(Collectors.toList());

        } catch (Exception e) {
            log.error("æ—¥å¿—åˆ†ç±»å¤±è´¥", e);
            return Collections.emptyList();
        }
    }

    /**
     * æ—¥å¿—å¼‚å¸¸æ£€æµ‹
     */
    @Transactional(readOnly = true)
    public List<LogAnomaly> detectLogAnomalies(LogSearchRequest request) {
        try {
            LogSearchResult searchResult = searchLogs(request);

            List<LogAnomaly> anomalies = new ArrayList<>();

            // 1. é”™è¯¯æ—¥å¿—å¼‚å¸¸æ£€æµ‹
            List<LogEntry> errorLogs = searchResult.getLogs().stream()
                .filter(log -> "ERROR".equals(log.getLevel()))
                .collect(Collectors.toList());

            if (isErrorRateAnomalous(errorLogs.size(), searchResult.getTotal())) {
                anomalies.add(LogAnomaly.builder()
                    .type(LogAnomalyType.ERROR_RATE_HIGH)
                    .description("é”™è¯¯æ—¥å¿—æ•°é‡å¼‚å¸¸")
                    .count(errorLogs.size())
                    .severity(Severity.HIGH)
                    .build());
            }

            // 2. å¼‚å¸¸å †æ ˆåˆ†æ
            for (LogEntry log : errorLogs) {
                if (StringUtils.hasText(log.getException())) {
                    List<String> stackTrace = parseStackTrace(log.getException());

                    // æ£€æµ‹æ–°çš„å¼‚å¸¸æ¨¡å¼
                    if (isNewExceptionPattern(stackTrace)) {
                        anomalies.add(LogAnomaly.builder()
                            .type(LogAnomalyType.NEW_EXCEPTION)
                            .description("æ£€æµ‹åˆ°æ–°çš„å¼‚å¸¸æ¨¡å¼")
                            .exceptionType(stackTrace.get(0))
                            .severity(Severity.HIGH)
                            .build());
                    }

                    // æ£€æµ‹å¼‚å¸¸é¢‘æ¬¡
                    int frequency = getExceptionFrequency(stackTrace.get(0), request);
                    if (frequency > 10) { // é˜ˆå€¼å¯é…ç½®
                        anomalies.add(LogAnomaly.builder()
                            .type(LogAnomalyType.EXCEPTION_FREQUENCY_HIGH)
                            .description("å¼‚å¸¸é¢‘æ¬¡è¿‡é«˜: " + frequency)
                            .exceptionType(stackTrace.get(0))
                            .frequency(frequency)
                            .severity(Severity.MEDIUM)
                            .build());
                    }
                }
            }

            // 3. æ—¥å¿—æ¨¡å¼å¼‚å¸¸æ£€æµ‹
            Map<String, Long> logPatterns = searchResult.getLogs().stream()
                .map(this::extractLogPattern)
                .collect(Collectors.groupingBy(
                    Function.identity(),
                    Collectors.counting()
                ));

            // æ£€æµ‹ä½é¢‘æ¨¡å¼
            logPatterns.entrySet().stream()
                .filter(entry -> entry.getValue() == 1)
                .forEach(entry -> {
                    anomalies.add(LogAnomaly.builder()
                        .type(LogAnomalyType.RARE_LOG_PATTERN)
                        .description("æ£€æµ‹åˆ°ä½é¢‘æ—¥å¿—æ¨¡å¼")
                        .pattern(entry.getKey())
                        .severity(Severity.LOW)
                        .build());
                });

            return anomalies;

        } catch (Exception e) {
            log.error("æ—¥å¿—å¼‚å¸¸æ£€æµ‹å¤±è´¥", e);
            return Collections.emptyList();
        }
    }

    /**
     * æ—¥å¿—è¶‹åŠ¿åˆ†æ
     */
    @Transactional(readOnly = true)
    public LogTrendAnalysis analyzeLogTrends(LogTrendRequest request) {
        try {
            Map<LogType, List<TimeSeriesData>> trends = new HashMap<>();

            // åˆ†æé”™è¯¯æ—¥å¿—è¶‹åŠ¿
            List<TimeSeriesData> errorTrend = queryLogTrend(
                "ERROR",
                request.getService(),
                request.getStartTime(),
                request.getEndTime()
            );
            trends.put(LogType.ERROR, errorTrend);

            // åˆ†æè­¦å‘Šæ—¥å¿—è¶‹åŠ¿
            List<TimeSeriesData> warnTrend = queryLogTrend(
                "WARN",
                request.getService(),
                request.getStartTime(),
                request.getEndTime()
            );
            trends.put(LogType.WARN, warnTrend);

            // åˆ†æä¿¡æ¯æ—¥å¿—è¶‹åŠ¿
            List<TimeSeriesData> infoTrend = queryLogTrend(
                "INFO",
                request.getService(),
                request.getStartTime(),
                request.getEndTime()
            );
            trends.put(LogType.INFO, infoTrend);

            // è®¡ç®—è¶‹åŠ¿æŒ‡æ ‡
            Map<LogType, TrendMetrics> metrics = new HashMap<>();
            trends.forEach((type, data) -> {
                TrendMetrics metric = calculateTrendMetrics(data);
                metrics.put(type, metric);
            });

            // æ£€æµ‹å¼‚å¸¸è¶‹åŠ¿
            List<TrendAnomaly> anomalies = detectTrendAnomalies(trends);

            return LogTrendAnalysis.builder()
                .trends(trends)
                .metrics(metrics)
                .anomalies(anomalies)
                .startTime(request.getStartTime())
                .endTime(request.getEndTime())
                .build();

        } catch (Exception e) {
            log.error("æ—¥å¿—è¶‹åŠ¿åˆ†æå¤±è´¥", e);
            return LogTrendAnalysis.builder().build();
        }
    }

    /**
     * å®æ—¶æ—¥å¿—ç›‘æ§
     */
    @Transactional(readOnly = true)
    public List<RealTimeLogAlert> monitorRealTimeLogs(String service) {
        try {
            // æŸ¥è¯¢æœ€è¿‘5åˆ†é’Ÿçš„æ—¥å¿—
            LogSearchRequest request = LogSearchRequest.builder()
                .service(service)
                .startTime(Instant.now().minus(Duration.ofMinutes(5)))
                .endTime(Instant.now())
                .build();

            LogSearchResult result = searchLogs(request);

            List<RealTimeLogAlert> alerts = new ArrayList<>();

            // å®æ—¶é”™è¯¯ç‡ç›‘æ§
            double errorRate = calculateErrorRate(result.getLogs());
            if (errorRate > 0.05) { // 5%é”™è¯¯ç‡é˜ˆå€¼
                alerts.add(RealTimeLogAlert.builder()
                    .service(service)
                    .type(RealTimeAlertType.ERROR_RATE_HIGH)
                    .description("å®æ—¶é”™è¯¯ç‡è¿‡é«˜: " + (errorRate * 100) + "%")
                    .value(errorRate * 100)
                    .severity(Severity.HIGH)
                    .timestamp(Instant.now())
                    .build());
            }

            // å®æ—¶å¼‚å¸¸æ—¥å¿—ç›‘æ§
            List<LogAnomaly> anomalies = detectLogAnomalies(request);
            anomalies.forEach(anomaly -> {
                alerts.add(RealTimeLogAlert.builder()
                    .service(service)
                    .type(RealTimeAlertType.LOG_ANOMALY)
                    .description(anomaly.getDescription())
                    .value(anomaly.getCount().doubleValue())
                    .severity(anomaly.getSeverity())
                    .timestamp(Instant.now())
                    .build());
            });

            return alerts;

        } catch (Exception e) {
            log.error("å®æ—¶æ—¥å¿—ç›‘æ§å¤±è´¥", e);
            return Collections.emptyList();
        }
    }

    private LogSearchResult parseLogSearchResponse(SearchResponse response) {
        List<LogEntry> logs = new ArrayList<>();

        for (SearchHit hit : response.getHits().getHits()) {
            try {
                Map<String, Object> source = hit.getSourceAsMap();

                LogEntry log = LogEntry.builder()
                    .id(hit.getId())
                    .timestamp(Instant.ofEpochMilli((Long) source.get("@timestamp")))
                    .service((String) source.get("service"))
                    .level((String) source.get("level"))
                    .message((String) source.get("message"))
                    .logger((String) source.get("logger"))
                    .exception((String) source.get("exception"))
                    .stackTrace((String) source.get("stackTrace"))
                    .traceId((String) source.get("traceId"))
                    .spanId((String) source.get("spanId"))
                    .build();

                // é«˜äº®æ˜¾ç¤º
                if (hit.getHighlightFields() != null) {
                    Highlight messageHighlight = hit.getHighlightFields().get("message");
                    if (messageHighlight != null && !messageHighlight.getFragments().isEmpty()) {
                        log.setMessageHighlight(messageHighlight.getFragments().get(0).string());
                    }

                    Highlight exceptionHighlight = hit.getHighlightFields().get("exception");
                    if (exceptionHighlight != null && !exceptionHighlight.getFragments().isEmpty()) {
                        log.setExceptionHighlight(exceptionHighlight.getFragments().get(0).string());
                    }
                }

                logs.add(log);

            } catch (Exception e) {
                log.warn("è§£ææ—¥å¿—æ¡ç›®å¤±è´¥", e);
            }
        }

        return LogSearchResult.builder()
            .logs(logs)
            .total(response.getHits().getTotalHits().value)
            .build();
    }

    private String extractLogPattern(LogEntry log) {
        // æå–æ—¥å¿—æ¨¡å¼ï¼Œä¾‹å¦‚ç§»é™¤å…·ä½“æ•°å€¼å’Œæ—¶é—´
        String pattern = log.getMessage();

        // ç§»é™¤IPåœ°å€
        pattern = pattern.replaceAll("\\d+\\.\\d+\\.\\d+\\.\\d+", "IP");

        // ç§»é™¤UUID
        pattern = pattern.replaceAll("[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}", "UUID");

        // ç§»é™¤æ•°å­—
        pattern = pattern.replaceAll("\\d+", "NUMBER");

        return pattern;
    }

    private List<String> parseStackTrace(String exception) {
        return Arrays.asList(exception.split("\n"));
    }

    private List<TimeSeriesData> queryLogTrend(String level, String service,
                                               Instant startTime, Instant endTime) {
        // æ„å»ºESæŸ¥è¯¢
        SearchRequest searchRequest = new SearchRequest("logs-*")
            .source(SearchSourceBuilder.searchSource()
                .query(QueryBuilders.boolQuery()
                    .must(QueryBuilders.termQuery("level", level))
                    .must(QueryBuilders.termQuery("service", service))
                    .must(QueryBuilders.rangeQuery("@timestamp")
                        .gte(startTime.toEpochMilli())
                        .lte(endTime.toEpochMilli())))
                .size(10000));

        SearchResponse response = elasticSearchService.search(searchRequest);

        // æŒ‰æ—¶é—´èšåˆ
        Map<String, Long> timeCounts = new HashMap<>();
        for (SearchHit hit : response.getHits().getHits()) {
            Map<String, Object> source = hit.getSourceAsMap();
            String timestamp = source.get("@timestamp").toString();
            // æˆªå–åˆ°åˆ†é’Ÿ
            timestamp = timestamp.substring(0, 16);
            timeCounts.put(timestamp, timeCounts.getOrDefault(timestamp, 0L) + 1L);
        }

        // è½¬æ¢ä¸ºæ—¶é—´åºåˆ—æ•°æ®
        return timeCounts.entrySet().stream()
            .map(entry -> {
                LocalDateTime time = LocalDateTime.parse(entry.getKey(), DateTimeFormatter.ISO_LOCAL_DATE_TIME);
                return new TimeSeriesData(
                    Instant.from(time.atZone(ZoneId.systemDefault())),
                    entry.getValue().doubleValue()
                );
            })
            .sorted(Comparator.comparing(TimeSeriesData::getTimestamp))
            .collect(Collectors.toList());
    }

    private TrendMetrics calculateTrendMetrics(List<TimeSeriesData> data) {
        if (data.size() < 2) {
            return TrendMetrics.builder().build();
        }

        double[] values = data.stream().mapToDouble(TimeSeriesData::getValue).toArray();

        // è®¡ç®—è¶‹åŠ¿
        double trend = calculateSlope(values);

        // è®¡ç®—å˜åŒ–ç‡
        double changeRate = (values[values.length - 1] - values[0]) / values[0];

        return TrendMetrics.builder()
            .trend(trend)
            .changeRate(changeRate)
            .min(Arrays.stream(values).min().orElse(0))
            .max(Arrays.stream(values).max().orElse(0))
            .avg(Arrays.stream(values).average().orElse(0))
            .build();
    }

    private double calculateSlope(double[] values) {
        int n = values.length;
        double sumX = 0, sumY = 0, sumXY = 0, sumXX = 0;

        for (int i = 0; i < n; i++) {
            sumX += i;
            sumY += values[i];
            sumXY += i * values[i];
            sumXX += i * i;
        }

        return (n * sumXY - sumX * sumY) / (n * sumXX - sumX * sumX);
    }

    private boolean isErrorRateAnomalous(int errorCount, long totalCount) {
        double errorRate = (double) errorCount / totalCount;
        return errorRate > 0.1; // 10%é”™è¯¯ç‡é˜ˆå€¼
    }

    private boolean isNewExceptionPattern(List<String> stackTrace) {
        // æ£€æŸ¥æ˜¯å¦ä¸ºæ–°çš„å¼‚å¸¸æ¨¡å¼
        return true; // ç®€åŒ–å®ç°
    }

    private int getExceptionFrequency(String exceptionType, LogSearchRequest request) {
        // æŸ¥è¯¢å¼‚å¸¸é¢‘æ¬¡
        return 10; // ç®€åŒ–å®ç°
    }
}
```

### 2. æ—¥å¿—åˆ†æAPI

```java
/**
 * æ—¥å¿—åˆ†æAPI
 */
@RestController
@RequestMapping("/api/aiops/logs")
@Api(tags = "æ—¥å¿—åˆ†æ")
@Validated
public class LogAnalysisController {

    @Autowired
    private LogAnalysisService logAnalysisService;

    /**
     * æœç´¢æ—¥å¿—
     */
    @PostMapping("/search")
    @ApiOperation("æœç´¢æ—¥å¿—")
    public Result<LogSearchResult> searchLogs(@Valid @RequestBody LogSearchRequest request) {
        LogSearchResult result = logAnalysisService.searchLogs(request);
        return Result.success(result);
    }

    /**
     * æ—¥å¿—åˆ†ç±»
     */
    @PostMapping("/classify")
    @ApiOperation("æ—¥å¿—åˆ†ç±»")
    public Result<List<LogCategory>> classifyLogs(@Valid @RequestBody LogSearchRequest request) {
        List<LogCategory> categories = logAnalysisService.classifyLogs(request);
        return Result.success(categories);
    }

    /**
     * æ—¥å¿—å¼‚å¸¸æ£€æµ‹
     */
    @PostMapping("/anomaly")
    @ApiOperation("æ—¥å¿—å¼‚å¸¸æ£€æµ‹")
    public Result<List<LogAnomaly>> detectLogAnomalies(@Valid @RequestBody LogSearchRequest request) {
        List<LogAnomaly> anomalies = logAnalysisService.detectLogAnomalies(request);
        return Result.success(anomalies);
    }

    /**
     * æ—¥å¿—è¶‹åŠ¿åˆ†æ
     */
    @PostMapping("/trends")
    @ApiOperation("æ—¥å¿—è¶‹åŠ¿åˆ†æ")
    public Result<LogTrendAnalysis> analyzeLogTrends(@Valid @RequestBody LogTrendRequest request) {
        LogTrendAnalysis result = logAnalysisService.analyzeLogTrends(request);
        return Result.success(result);
    }

    /**
     * å®æ—¶æ—¥å¿—ç›‘æ§
     */
    @GetMapping("/realtime/{service}")
    @ApiOperation("å®æ—¶æ—¥å¿—ç›‘æ§")
    public Result<List<RealTimeLogAlert>> monitorRealTimeLogs(@PathVariable String service) {
        List<RealTimeLogAlert> alerts = logAnalysisService.monitorRealTimeLogs(service);
        return Result.success(alerts);
    }
}
```

---

## ğŸ¤– è‡ªåŠ¨åŒ–è¿ç»´

### 1. è‡ªåŠ¨å·¡æ£€ç³»ç»Ÿ

```java
/**
 * è‡ªåŠ¨å·¡æ£€æœåŠ¡
 */
@Service
public class AutoInspectionService {

    @Autowired
    private PrometheusService prometheusService;

    @Autowired
    private ElasticSearchService elasticSearchService;

    @Autowired
    private KubernetesService kubernetesService;

    @Autowired
    private NotificationService notificationService;

    /**
     * æ‰§è¡Œç³»ç»Ÿå·¡æ£€
     */
    @Scheduled(fixedRate = 300000) // æ¯5åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
    public void performSystemInspection() {
        log.info("å¼€å§‹æ‰§è¡Œç³»ç»Ÿå·¡æ£€");

        List<InspectionResult> results = new ArrayList<>();

        try {
            // 1. æ£€æŸ¥ç³»ç»ŸæŒ‡æ ‡
            results.addAll(inspectSystemMetrics());

            // 2. æ£€æŸ¥åº”ç”¨çŠ¶æ€
            results.addAll(inspectApplicationStatus());

            // 3. æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
            results.addAll(inspectDatabaseStatus());

            // 4. æ£€æŸ¥å®¹å™¨çŠ¶æ€
            results.addAll(inspectContainerStatus());

            // 5. æ£€æŸ¥ç£ç›˜ç©ºé—´
            results.addAll(inspectDiskSpace());

            // 6. æ£€æŸ¥ç½‘ç»œè¿æ¥
            results.addAll(inspectNetworkConnectivity());

            // 7. æ£€æŸ¥è¯ä¹¦è¿‡æœŸ
            results.addAll(inspectCertificateExpiry());

            // å¤„ç†å·¡æ£€ç»“æœ
            processInspectionResults(results);

        } catch (Exception e) {
            log.error("ç³»ç»Ÿå·¡æ£€å¤±è´¥", e);

            // å‘é€å·¡æ£€å¤±è´¥é€šçŸ¥
            notificationService.sendAlert(
                AlertLevel.CRITICAL,
                "ç³»ç»Ÿå·¡æ£€å¤±è´¥",
                "æ‰§è¡Œç³»ç»Ÿå·¡æ£€æ—¶å‘ç”Ÿé”™è¯¯: " + e.getMessage()
            );
        }
    }

    /**
     * æ£€æŸ¥ç³»ç»ŸæŒ‡æ ‡
     */
    private List<InspectionResult> inspectSystemMetrics() {
        List<InspectionResult> results = new ArrayList<>();

        // CPUä½¿ç”¨ç‡æ£€æŸ¥
        Double cpuUsage = prometheusService.queryInstantValue("avg(rate(container_cpu_usage_seconds_total[5m]))");
        if (cpuUsage != null && cpuUsage > 0.8) {
            results.add(InspectionResult.builder()
                .category(InspectionCategory.SYSTEM_METRICS)
                .item("CPUä½¿ç”¨ç‡")
                .status(InspectionStatus.WARNING)
                .message("CPUä½¿ç”¨ç‡è¿‡é«˜: " + (cpuUsage * 100) + "%")
                .value(cpuUsage)
                .threshold(0.8)
                .recommendation("è€ƒè™‘å¢åŠ CPUèµ„æºæˆ–ä¼˜åŒ–åº”ç”¨æ€§èƒ½")
                .build());
        }

        // å†…å­˜ä½¿ç”¨ç‡æ£€æŸ¥
        Double memoryUsage = prometheusService.queryInstantValue("avg(container_memory_usage_bytes) / avg(container_spec_memory_limit_bytes)");
        if (memoryUsage != null && memoryUsage > 0.85) {
            results.add(InspectionResult.builder()
                .category(InspectionCategory.SYSTEM_METRICS)
                .item("å†…å­˜ä½¿ç”¨ç‡")
                .status(InspectionStatus.WARNING)
                .message("å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: " + (memoryUsage * 100) + "%")
                .value(memoryUsage)
                .threshold(0.85)
                .recommendation("è€ƒè™‘å¢åŠ å†…å­˜èµ„æºæˆ–ä¼˜åŒ–å†…å­˜ä½¿ç”¨")
                .build());
        }

        // ç£ç›˜ä½¿ç”¨ç‡æ£€æŸ¥
        Double diskUsage = prometheusService.queryInstantValue("1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)");
        if (diskUsage != null && diskUsage > 0.9) {
            results.add(InspectionResult.builder()
                .category(InspectionCategory.SYSTEM_METRICS)
                .item("ç£ç›˜ä½¿ç”¨ç‡")
                .status(InspectionStatus.CRITICAL)
                .message("ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: " + (diskUsage * 100) + "%")
                .value(diskUsage)
                .threshold(0.9)
                .recommendation("ç«‹å³æ¸…ç†ç£ç›˜ç©ºé—´æˆ–æ‰©å®¹")
                .build());
        }

        return results;
    }

    /**
     * æ£€æŸ¥åº”ç”¨çŠ¶æ€
     */
    private List<InspectionResult> inspectApplicationStatus() {
        List<InspectionResult> results = new ArrayList<>();

        // è·å–æ‰€æœ‰PodçŠ¶æ€
        List<Pod> pods = kubernetesService.listPods();

        for (Pod pod : pods) {
            // æ£€æŸ¥PodçŠ¶æ€
            PodStatus status = pod.getStatus();
            if (!"Running".equals(status.getPhase())) {
                results.add(InspectionResult.builder()
                    .category(InspectionCategory.APPLICATION)
                    .item("PodçŠ¶æ€")
                    .status(InspectionStatus.CRITICAL)
                    .message("Pod " + pod.getMetadata().getName() + " çŠ¶æ€å¼‚å¸¸: " + status.getPhase())
                    .resource(pod.getMetadata().getName())
                    .recommendation("æ£€æŸ¥Podæ—¥å¿—å¹¶é‡å¯å¤±è´¥çš„Pod")
                    .build());
            }

            // æ£€æŸ¥å®¹å™¨é‡å¯æ¬¡æ•°
            for (ContainerStatus containerStatus : status.getContainerStatuses()) {
                int restartCount = containerStatus.getRestartCount();
                if (restartCount > 5) {
                    results.add(InspectionResult.builder()
                        .category(InspectionCategory.APPLICATION)
                        .item("å®¹å™¨é‡å¯")
                        .status(InspectionStatus.WARNING)
                        .message("å®¹å™¨ " + containerStatus.getName() + " é‡å¯æ¬¡æ•°è¿‡å¤š: " + restartCount)
                        .resource(containerStatus.getName())
                        .recommendation("æ£€æŸ¥åº”ç”¨æ—¥å¿—å¹¶è°ƒæŸ¥é‡å¯åŸå› ")
                        .build());
                }
            }
        }

        return results;
    }

    /**
     * æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
     */
    private List<InspectionResult> inspectDatabaseStatus() {
        List<InspectionResult> results = new ArrayList<>();

        // MySQLçŠ¶æ€æ£€æŸ¥
        try {
            String mysqlStatus = queryMySQLStatus();
            if (!"running".equalsIgnoreCase(mysqlStatus)) {
                results.add(InspectionResult.builder()
                    .category(InspectionCategory.DATABASE)
                    .item("MySQLçŠ¶æ€")
                    .status(InspectionStatus.CRITICAL)
                    .message("MySQLæœåŠ¡æœªæ­£å¸¸è¿è¡Œ")
                    .recommendation("é‡å¯MySQLæœåŠ¡")
                    .build());
            }

            // è¿æ¥æ•°æ£€æŸ¥
            Integer connections = queryMySQLConnections();
            if (connections != null && connections > 1000) {
                results.add(InspectionResult.builder()
                    .category(InspectionCategory.DATABASE)
                    .item("MySQLè¿æ¥æ•°")
                    .status(InspectionStatus.WARNING)
                    .message("MySQLè¿æ¥æ•°è¿‡é«˜: " + connections)
                    .value(connections.doubleValue())
                    .recommendation("æ£€æŸ¥è¿æ¥æ± é…ç½®å’Œé•¿è¿æ¥")
                    .build());
            }

            // æ…¢æŸ¥è¯¢æ£€æŸ¥
            Integer slowQueries = queryMySQLSlowQueries();
            if (slowQueries != null && slowQueries > 100) {
                results.add(InspectionResult.builder()
                    .category(InspectionCategory.DATABASE)
                    .item("MySQLæ…¢æŸ¥è¯¢")
                    .status(InspectionStatus.WARNING)
                    .message("æ…¢æŸ¥è¯¢æ•°é‡è¿‡å¤š: " + slowQueries)
                    .value(slowQueries.doubleValue())
                    .recommendation("ä¼˜åŒ–æ…¢æŸ¥è¯¢SQLè¯­å¥")
                    .build());
            }

        } catch (Exception e) {
            results.add(InspectionResult.builder()
                .category(InspectionCategory.DATABASE)
                .item("æ•°æ®åº“æ£€æŸ¥")
                .status(InspectionStatus.ERROR)
                .message("æ•°æ®åº“çŠ¶æ€æ£€æŸ¥å¤±è´¥: " + e.getMessage())
                .build());
        }

        return results;
    }

    /**
     * æ£€æŸ¥å®¹å™¨çŠ¶æ€
     */
    private List<InspectionResult> inspectContainerStatus() {
        List<InspectionResult> results = new ArrayList<>();

        // æ£€æŸ¥å®¹å™¨é•œåƒç‰ˆæœ¬
        Map<String, String> imageVersions = kubernetesService.getImageVersions();

        for (Map.Entry<String, String> entry : imageVersions.entrySet()) {
            String image = entry.getValue();

            // æ£€æŸ¥æ˜¯å¦ä¸ºæœ€æ–°ç‰ˆæœ¬
            if (isOutdatedImage(image)) {
                results.add(InspectionResult.builder()
                    .category(InspectionCategory.CONTAINER)
                    .item("é•œåƒç‰ˆæœ¬")
                    .status(InspectionStatus.WARNING)
                    .message("å®¹å™¨ " + entry.getKey() + " ä½¿ç”¨è¿‡æœŸé•œåƒ: " + image)
                    .resource(entry.getKey())
                    .recommendation("æ›´æ–°å®¹å™¨é•œåƒåˆ°æœ€æ–°ç‰ˆæœ¬")
                    .build());
            }
        }

        // æ£€æŸ¥å®¹å™¨èµ„æºé™åˆ¶
        for (Pod pod : kubernetesService.listPods()) {
            for (Container container : pod.getSpec().getContainers()) {
                ResourceRequirements resources = container.getResources();

                if (resources.getRequests() == null || resources.getLimits() == null) {
                    results.add(InspectionResult.builder()
                        .category(InspectionCategory.CONTAINER)
                        .item("èµ„æºé™åˆ¶")
                        .status(InspectionStatus.WARNING)
                        .message("å®¹å™¨ " + container.getName() + " æœªé…ç½®èµ„æºé™åˆ¶")
                        .resource(container.getName())
                        .recommendation("ä¸ºå®¹å™¨é…ç½®é€‚å½“çš„CPUå’Œå†…å­˜é™åˆ¶")
                        .build());
                }
            }
        }

        return results;
    }

    /**
     * è‡ªåŠ¨ä¿®å¤é—®é¢˜
     */
    @EventListener
    @Async
    public void handleInspectionResults(List<InspectionResult> results) {
        for (InspectionResult result : results) {
            if (result.getStatus() == InspectionStatus.CRITICAL) {
                try {
                    autoFixCriticalIssue(result);
                } catch (Exception e) {
                    log.error("è‡ªåŠ¨ä¿®å¤å¤±è´¥: {}", result.getItem(), e);

                    // å‘é€ä¿®å¤å¤±è´¥é€šçŸ¥
                    notificationService.sendAlert(
                        AlertLevel.CRITICAL,
                        "è‡ªåŠ¨ä¿®å¤å¤±è´¥",
                        "ä¿®å¤" + result.getItem() + "æ—¶å‘ç”Ÿé”™è¯¯: " + e.getMessage()
                    );
                }
            }
        }
    }

    private void autoFixCriticalIssue(InspectionResult result) {
        switch (result.getCategory()) {
            case SYSTEM_METRICS:
                if ("ç£ç›˜ä½¿ç”¨ç‡".equals(result.getItem())) {
                    // è‡ªåŠ¨æ¸…ç†æ—¥å¿—æ–‡ä»¶
                    cleanupLogFiles();
                }
                break;

            case APPLICATION:
                if ("PodçŠ¶æ€".equals(result.getItem())) {
                    // é‡å¯å¤±è´¥çš„Pod
                    restartFailedPod(result.getResource());
                }
                break;

            case DATABASE:
                if ("MySQLè¿æ¥æ•°".equals(result.getItem())) {
                    // æ¸…ç†ç©ºé—²è¿æ¥
                    cleanupIdleConnections();
                }
                break;

            default:
                log.warn("æš‚ä¸æ”¯æŒè‡ªåŠ¨ä¿®å¤: {}", result.getItem());
        }
    }

    private void cleanupLogFiles() {
        try {
            // æ¸…ç†7å¤©å‰çš„æ—¥å¿—æ–‡ä»¶
            ProcessBuilder pb = new ProcessBuilder(
                "find",
                "/var/log",
                "-type",
                "f",
                "-name",
                "*.log",
                "-mtime",
                "+7",
                "-delete"
            );
            pb.start();

            log.info("è‡ªåŠ¨æ¸…ç†æ—¥å¿—æ–‡ä»¶å®Œæˆ");
        } catch (Exception e) {
            log.error("æ¸…ç†æ—¥å¿—æ–‡ä»¶å¤±è´¥", e);
        }
    }

    private void restartFailedPod(String podName) {
        try {
            kubernetesService.deletePod(podName);
            log.info("å·²é‡å¯Pod: {}", podName);
        } catch (Exception e) {
            log.error("é‡å¯Podå¤±è´¥: {}", podName, e);
        }
    }

    private void cleanupIdleConnections() {
        try {
            // æ‰§è¡Œæ•°æ®åº“è¿æ¥æ¸…ç†SQL
            executeSQL("SET GLOBAL innodb_expire_log_tracks_time = 60");
            log.info("å·²æ¸…ç†ç©ºé—²æ•°æ®åº“è¿æ¥");
        } catch (Exception e) {
            log.error("æ¸…ç†ç©ºé—²è¿æ¥å¤±è´¥", e);
        }
    }

    private String queryMySQLStatus() {
        // å®ç°MySQLçŠ¶æ€æŸ¥è¯¢
        return "running";
    }

    private Integer queryMySQLConnections() {
        // å®ç°è¿æ¥æ•°æŸ¥è¯¢
        return 100;
    }

    private Integer queryMySQLSlowQueries() {
        // å®ç°æ…¢æŸ¥è¯¢ç»Ÿè®¡
        return 50;
    }

    private boolean isOutdatedImage(String image) {
        // æ£€æŸ¥é•œåƒæ˜¯å¦ä¸ºè¿‡æœŸç‰ˆæœ¬
        return false;
    }
}
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. åŸºäºæœºå™¨å­¦ä¹ çš„æ€§èƒ½é¢„æµ‹

```java
/**
 * æ€§èƒ½é¢„æµ‹æœåŠ¡
 */
@Service
public class PerformancePredictionService {

    @Autowired
    private PrometheusService prometheusService;

    @Autowired
    private MachineLearningService mlService;

    /**
     * é¢„æµ‹CPUä½¿ç”¨è¶‹åŠ¿
     */
    public PredictionResult predictCPUUsage(Duration horizon) {
        // è·å–å†å²CPUæ•°æ®
        List<TimeSeriesData> historicalData = prometheusService.queryRange(
            "avg(rate(container_cpu_usage_seconds_total[1m]))",
            Instant.now().minus(Duration.ofDays(30)),
            Instant.now(),
            Duration.ofMinutes(5)
        );

        // ä½¿ç”¨LSTMæ¨¡å‹é¢„æµ‹
        List<TimeSeriesData> predictions = mlService.predictWithLSTM(historicalData, horizon);

        return PredictionResult.builder()
            .metric("cpu_usage")
            .horizon(horizon)
            .predictions(predictions)
            .confidence(calculateConfidence(predictions))
            .build();
    }

    /**
     * é¢„æµ‹å†…å­˜ä½¿ç”¨è¶‹åŠ¿
     */
    public PredictionResult predictMemoryUsage(Duration horizon) {
        List<TimeSeriesData> historicalData = prometheusService.queryRange(
            "avg(container_memory_usage_bytes)",
            Instant.now().minus(Duration.ofDays(30)),
            Instant.now(),
            Duration.ofMinutes(5)
        );

        List<TimeSeriesData> predictions = mlService.predictWithLSTM(historicalData, horizon);

        return PredictionResult.builder()
            .metric("memory_usage")
            .horizon(horizon)
            .predictions(predictions)
            .confidence(calculateConfidence(predictions))
            .build();
    }

    /**
     * é¢„æµ‹ç£ç›˜IO
     */
    public PredictionResult predictDiskIO(Duration horizon) {
        List<TimeSeriesData> historicalData = prometheusService.queryRange(
            "sum(rate(container_fs_reads_bytes_total[1m])) + sum(rate(container_fs_writes_bytes_total[1m]))",
            Instant.now().minus(Duration.ofDays(30)),
            Instant.now(),
            Duration.ofMinutes(5)
        );

        List<TimeSeriesData> predictions = mlService.predictWithLSTM(historicalData, horizon);

        return PredictionResult.builder()
            .metric("disk_io")
            .horizon(horizon)
            .predictions(predictions)
            .confidence(calculateConfidence(predictions))
            .build();
    }

    /**
     * å®¹é‡è§„åˆ’å»ºè®®
     */
    public CapacityPlanningResult generateCapacityPlanning() {
        // é¢„æµ‹æœªæ¥1ä¸ªæœˆçš„èµ„æºä½¿ç”¨
        PredictionResult cpuPrediction = predictCPUUsage(Duration.ofDays(30));
        PredictionResult memoryPrediction = predictMemoryUsage(Duration.ofDays(30));
        PredictionResult diskPrediction = predictDiskIO(Duration.ofDays(30));

        CapacityPlanningResult.Builder builder = CapacityPlanningResult.builder()
            .predictionTime(Instant.now())
            .horizon(Duration.ofDays(30));

        // CPUå®¹é‡å»ºè®®
        double maxCpuPredicted = cpuPrediction.getPredictions().stream()
            .mapToDouble(TimeSeriesData::getValue)
            .max()
            .orElse(0);

        if (maxCpuPredicted > 0.8) {
            builder.recommendation(CapacityRecommendation.builder()
                .type("CPU")
                .description("é¢„æµ‹CPUä½¿ç”¨ç‡å°†è¶…è¿‡80%")
                .currentUtilization(getCurrentCPUUtilization())
                .predictedUtilization(maxCpuPredicted)
                .recommendedAction("å»ºè®®å¢åŠ CPUæ ¸å¿ƒæ•°æˆ–ä¼˜åŒ–åº”ç”¨æ€§èƒ½")
                .priority(Priority.HIGH)
                .build());
        }

        // å†…å­˜å®¹é‡å»ºè®®
        double maxMemoryPredicted = memoryPrediction.getPredictions().stream()
            .mapToDouble(TimeSeriesData::getValue)
            .max()
            .orElse(0);

        if (maxMemoryPredicted > 0.85) {
            builder.recommendation(CapacityRecommendation.builder()
                .type("Memory")
                .description("é¢„æµ‹å†…å­˜ä½¿ç”¨ç‡å°†è¶…è¿‡85%")
                .currentUtilization(getCurrentMemoryUtilization())
                .predictedUtilization(maxMemoryPredicted)
                .recommendedAction("å»ºè®®å¢åŠ å†…å­˜å®¹é‡æˆ–ä¼˜åŒ–å†…å­˜ä½¿ç”¨")
                .priority(Priority.HIGH)
                .build());
        }

        return builder.build();
    }

    private double calculateConfidence(List<TimeSeriesData> predictions) {
        // è®¡ç®—é¢„æµ‹ç½®ä¿¡åº¦
        return 0.85; // ç®€åŒ–å®ç°
    }

    private double getCurrentCPUUtilization() {
        return prometheusService.queryInstantValue("avg(rate(container_cpu_usage_seconds_total[5m]))")
            .orElse(0.0);
    }

    private double getCurrentMemoryUtilization() {
        return prometheusService.queryInstantValue("avg(container_memory_usage_bytes) / avg(container_spec_memory_limit_bytes)")
            .orElse(0.0);
    }
}
```

---

## ğŸ“‹ å®æ–½æ£€æŸ¥æ¸…å•

### å¼‚å¸¸æ£€æµ‹
- [ ] PrometheusæŒ‡æ ‡é‡‡é›†é…ç½®å®Œæˆ
- [ ] ç»Ÿè®¡å­¦å¼‚å¸¸æ£€æµ‹ç®—æ³•å®ç°
- [ ] æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹æ¨¡å‹è®­ç»ƒ
- [ ] å…³è”è§„åˆ™å¼‚å¸¸æ£€æµ‹å®ç°
- [ ] å¼‚å¸¸å‘Šè­¦é˜ˆå€¼é…ç½®
- [ ] å¼‚å¸¸æ£€æµ‹APIå¼€å‘å®Œæˆ

### æ ¹å› åˆ†æ
- [ ] æ ¹å› åˆ†æå¼•æ“å¼€å‘å®Œæˆ
- [ ] æŒ‡æ ‡å…³è”åˆ†æå®ç°
- [ ] æ—¥å¿—å¼‚å¸¸åˆ†æå®ç°
- [ ] è°ƒç”¨é“¾åˆ†æå®ç°
- [ ] é…ç½®å˜æ›´åˆ†æå®ç°
- [ ] èµ„æºä½¿ç”¨åˆ†æå®ç°
- [ ] ä¾èµ–æœåŠ¡åˆ†æå®ç°
- [ ] ç»¼åˆåˆ†æç®—æ³•ä¼˜åŒ–

### æ—¥å¿—åˆ†æ
- [ ] ELK Stackéƒ¨ç½²é…ç½®å®Œæˆ
- [ ] æ—¥å¿—é‡‡é›†é…ç½®ä¼˜åŒ–
- [ ] æ—¥å¿—æœç´¢åŠŸèƒ½å®ç°
- [ ] æ—¥å¿—åˆ†ç±»åŠŸèƒ½å®ç°
- [ ] æ—¥å¿—å¼‚å¸¸æ£€æµ‹ç®—æ³•å®ç°
- [ ] æ—¥å¿—è¶‹åŠ¿åˆ†æå®ç°
- [ ] å®æ—¶æ—¥å¿—ç›‘æ§å®ç°

### è‡ªåŠ¨åŒ–è¿ç»´
- [ ] è‡ªåŠ¨å·¡æ£€ä»»åŠ¡å¼€å‘
- [ ] ç³»ç»ŸæŒ‡æ ‡æ£€æŸ¥å®ç°
- [ ] åº”ç”¨çŠ¶æ€æ£€æŸ¥å®ç°
- [ ] æ•°æ®åº“çŠ¶æ€æ£€æŸ¥å®ç°
- [ ] è‡ªåŠ¨ä¿®å¤æœºåˆ¶å®ç°
- [ ] è‡ªåŠ¨åŒ–è„šæœ¬å¼€å‘

### æ€§èƒ½é¢„æµ‹
- [ ] LSTMæ¨¡å‹è®­ç»ƒå®Œæˆ
- [ ] å®¹é‡é¢„æµ‹ç®—æ³•å®ç°
- [ ] æ€§èƒ½è¶‹åŠ¿åˆ†æå®ç°
- [ ] èµ„æºä½¿ç”¨é¢„æµ‹å®ç°
- [ ] å®¹é‡è§„åˆ’å»ºè®®ç”Ÿæˆ

### ç›‘æ§å‘Šè­¦
- [ ] Grafanaä»ªè¡¨ç›˜å¼€å‘
- [ ] å‘Šè­¦è§„åˆ™é…ç½®
- [ ] å‘Šè­¦é€šçŸ¥æ¸ é“é…ç½®
- [ ] å‘Šè­¦å‡çº§æœºåˆ¶å®ç°
- [ ] å‘Šè­¦ç»Ÿè®¡åˆ†æ

---

**ç¼–åˆ¶ï¼š** æµ®æµ®é…± ğŸ±ï¼ˆçŒ«å¨˜å·¥ç¨‹å¸ˆï¼‰
**æ—¥æœŸï¼š** 2025-11-15
**çŠ¶æ€ï¼š** ğŸ“‹ æŒ‡å—å®Œæˆï¼Œå‡†å¤‡å®æ–½

**åŠ æ²¹å–µï½ æ™ºèƒ½è¿ç»´å¹³å°å³å°†å®Œæˆï¼** à¸…'Ï‰'à¸…
