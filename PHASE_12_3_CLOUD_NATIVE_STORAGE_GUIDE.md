# Phase 12.3: äº‘åŸç”Ÿå­˜å‚¨å®æ–½æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•å®æ–½äº‘åŸç”Ÿå­˜å‚¨è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬å¯¹è±¡å­˜å‚¨ã€åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿå’Œæ•°æ®åº“äº‘åŒ–ï¼Œæ„å»ºé«˜æ€§èƒ½ã€é«˜å¯ç”¨çš„å­˜å‚¨æ¶æ„ã€‚

---

## ğŸ—ï¸ äº‘åŸç”Ÿå­˜å‚¨æ¶æ„

### å­˜å‚¨å±‚æ¬¡æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      äº‘åŸç”Ÿå­˜å‚¨æ¶æ„                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   å¯¹è±¡å­˜å‚¨    â”‚  â”‚  åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ â”‚  â”‚   äº‘æ•°æ®åº“    â”‚           â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚           â”‚
â”‚  â”‚ â€¢ MinIO      â”‚  â”‚ â€¢ CephFS     â”‚  â”‚ â€¢ RDS MySQL  â”‚           â”‚
â”‚  â”‚ â€¢ S3 å…¼å®¹    â”‚  â”‚ â€¢ å—å­˜å‚¨      â”‚  â”‚ â€¢ PostgreSQL â”‚           â”‚
â”‚  â”‚ â€¢ CDN åŠ é€Ÿ   â”‚  â”‚ â€¢ POSIX      â”‚  â”‚ â€¢ MongoDB    â”‚           â”‚
â”‚  â”‚ â€¢ ç‰ˆæœ¬ç®¡ç†    â”‚  â”‚ â€¢ å¿«ç…§        â”‚  â”‚ â€¢ Redis Cloudâ”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚         â”‚                 â”‚                 â”‚                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   å¤‡ä»½å½’æ¡£    â”‚  â”‚   ç¾éš¾æ¢å¤   â”‚  â”‚   ç›‘æ§è¿ç»´   â”‚           â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚           â”‚
â”‚  â”‚ â€¢ å®šæœŸå¤‡ä»½   â”‚  â”‚ â€¢ ä¸»ä»å¤åˆ¶   â”‚  â”‚ â€¢ æ€§èƒ½ç›‘æ§   â”‚           â”‚
â”‚  â”‚ â€¢ ç”Ÿå‘½å‘¨æœŸç®¡ç†â”‚  â”‚ â€¢ è·¨åŒºåŸŸåŒæ­¥ â”‚  â”‚ â€¢ å®¹é‡è§„åˆ’   â”‚           â”‚
â”‚  â”‚ â€¢ å†·å­˜å‚¨     â”‚  â”‚ â€¢ è‡ªåŠ¨åˆ‡æ¢   â”‚  â”‚ â€¢ å‘Šè­¦é€šçŸ¥   â”‚           â”‚
â”‚  â”‚ â€¢ æ•°æ®åŠ å¯†   â”‚  â”‚ â€¢ å¤‡ä»½æ¢å¤   â”‚  â”‚ â€¢ å¥åº·æ£€æŸ¥   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    å­˜å‚¨æœåŠ¡å±‚                                 â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ â€¢ CSI é©±åŠ¨ (Container Storage Interface)                   â”‚ â”‚
â”‚  â”‚ â€¢ StorageClass (å­˜å‚¨ç±»)                                     â”‚ â”‚
â”‚  â”‚ â€¢ PersistentVolume (æŒä¹…åŒ–å·)                               â”‚ â”‚
â”‚  â”‚ â€¢ PersistentVolumeClaim (æŒä¹…åŒ–å·å£°æ˜)                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å­˜å‚¨ç±»å‹å¯¹æ¯”

| å­˜å‚¨ç±»å‹ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ | æ€§èƒ½ | æˆæœ¬ |
|----------|------|----------|------|------|
| **å¯¹è±¡å­˜å‚¨** | æµ·é‡å­˜å‚¨ã€S3åè®® | æ–‡ä»¶å­˜å‚¨ã€å¤‡ä»½ã€é™æ€èµ„æº | ä¸­ç­‰ | ä½ |
| **åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ** | POSIXå…¼å®¹ã€å…±äº«è®¿é—® | æ•°æ®åˆ†æã€å®¹å™¨ç¼–æ’ | é«˜ | ä¸­ |
| **å—å­˜å‚¨** | ä½å»¶è¿Ÿã€IOPSé«˜ | æ•°æ®åº“å­˜å‚¨ã€è™šæ‹ŸåŒ– | æœ€é«˜ | é«˜ |
| **äº‘æ•°æ®åº“** | æ‰˜ç®¡æœåŠ¡ã€é«˜å¯ç”¨ | ä¸šåŠ¡æ•°æ®åº“ã€ç¼“å­˜ | é«˜ | ä¸­ |

---

## ğŸ“¦ å¯¹è±¡å­˜å‚¨é›†æˆ (MinIO)

### 1. MinIO éƒ¨ç½²é…ç½®

```yaml
# minio-deployment.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: minio-storage

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: minio
  namespace: minio-storage
spec:
  replicas: 2
  selector:
    matchLabels:
      app: minio
  template:
    metadata:
      labels:
        app: minio
    spec:
      containers:
      - name: minio
        image: minio/minio:latest
        args:
          - server
          - /data
          - --console-address
          - :9001
        ports:
        - containerPort: 9000
          name: s3
        - containerPort: 9001
          name: console
        env:
        - name: MINIO_ROOT_USER
          value: "admin"
        - name: MINIO_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: minio-secret
              key: password
        volumeMounts:
        - name: data
          mountPath: /data
        resources:
          limits:
            cpu: 1000m
            memory: 2Gi
          requests:
            cpu: 500m
            memory: 1Gi
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: minio-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: minio
  namespace: minio-storage
spec:
  type: LoadBalancer
  ports:
  - port: 9000
    targetPort: 9000
    name: s3
  - port: 9001
    targetPort: 9001
    name: console
  selector:
    app: minio

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: minio-pvc
  namespace: minio-storage
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
  storageClassName: fast-ssd

---
apiVersion: v1
kind: Secret
metadata:
  name: minio-secret
  namespace: minio-storage
type: Opaque
data:
  password: cGFzc3dvcmQxMjM=  # base64ç¼–ç çš„å¯†ç 
```

### 2. MinIO Client é…ç½®

```bash
#!/bin/bash
# minio-setup.sh

MINIO_ENDPOINT="http://minio.minio-storage:9000"
MINIO_ACCESS_KEY="admin"
MINIO_SECRET_KEY="password123"

# å®‰è£… mc å®¢æˆ·ç«¯
wget https://dl.min.io/client/mc/release/linux-amd64/mc
chmod +x mc
mv mc /usr/local/bin/

# é…ç½® mc
mc alias set basebackend $MINIO_ENDPOINT $MINIO_ACCESS_KEY $MINIO_SECRET_KEY

# åˆ›å»º bucket
mc mb basebackend/files
mc mb basebackend/images
mc mb basebackend/backups
mc mb basebackend/logs

# è®¾ç½®å­˜å‚¨æ¡¶ç­–ç•¥
mc policy set public basebackend/files
mc policy set public basebackend/images

# é…ç½®ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ˆ30å¤©åè½¬å†·å­˜å‚¨ï¼‰
mc ilm add basebackend/backups --days 30 --storage-class GLACIER

# å¼€å¯ç‰ˆæœ¬ç®¡ç†
mc version enable basebackend/files

# å¼€å¯åŠ å¯†
mc encrypt set sse-s3 basebackend/files

echo "MinIO é…ç½®å®Œæˆ!"
```

### 3. Java SDK é›†æˆ

```java
/**
 * MinIO å¯¹è±¡å­˜å‚¨æœåŠ¡
 */
@Service
public class MinioStorageService {

    @Autowired
    private MinioClient minioClient;

    private final String bucketName = "basebackend-files";

    /**
     * ä¸Šä¼ æ–‡ä»¶
     */
    public void uploadFile(String objectName, InputStream inputStream,
                          String contentType, long size) {
        try {
            // æ£€æŸ¥ bucket æ˜¯å¦å­˜åœ¨
            boolean exists = minioClient.bucketExists(
                BucketExistsArgs.builder()
                    .bucket(bucketName)
                    .build()
            );

            if (!exists) {
                minioClient.createBucket(
                    CreateBucketArgs.builder()
                        .bucket(bucketName)
                        .build()
                );
            }

            // ä¸Šä¼ æ–‡ä»¶
            minioClient.putObject(
                PutObjectArgs.builder()
                    .bucket(bucketName)
                    .object(objectName)
                    .stream(inputStream, size, -1)
                    .contentType(contentType)
                    .build()
            );

            log.info("æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {}", objectName);
        } catch (Exception e) {
            log.error("æ–‡ä»¶ä¸Šä¼ å¤±è´¥", e);
            throw new StorageException("æ–‡ä»¶ä¸Šä¼ å¤±è´¥", e);
        }
    }

    /**
     * ä¸‹è½½æ–‡ä»¶
     */
    public InputStream downloadFile(String objectName) {
        try {
            GetObjectResponse response = minioClient.getObject(
                GetObjectArgs.builder()
                    .bucket(bucketName)
                    .object(objectName)
                    .build()
            );
            return response;
        } catch (Exception e) {
            log.error("æ–‡ä»¶ä¸‹è½½å¤±è´¥", e);
            throw new StorageException("æ–‡ä»¶ä¸‹è½½å¤±è´¥", e);
        }
    }

    /**
     * åˆ é™¤æ–‡ä»¶
     */
    public void deleteFile(String objectName) {
        try {
            minioClient.removeObject(
                RemoveObjectArgs.builder()
                    .bucket(bucketName)
                    .object(objectName)
                    .build()
            );
            log.info("æ–‡ä»¶åˆ é™¤æˆåŠŸ: {}", objectName);
        } catch (Exception e) {
            log.error("æ–‡ä»¶åˆ é™¤å¤±è´¥", e);
            throw new StorageException("æ–‡ä»¶åˆ é™¤å¤±è´¥", e);
        }
    }

    /**
     * è·å–æ–‡ä»¶è®¿é—®URL
     */
    public String getFileUrl(String objectName, int expirySeconds) {
        try {
            return minioClient.presignedGetObject(
                bucketName, objectName, expirySeconds
            );
        } catch (Exception e) {
            log.error("è·å–æ–‡ä»¶URLå¤±è´¥", e);
            throw new StorageException("è·å–æ–‡ä»¶URLå¤±è´¥", e);
        }
    }

    /**
     * å¤åˆ¶æ–‡ä»¶
     */
    public void copyFile(String sourceObject, String targetObject) {
        try {
            CopyObjectResponse response = minioClient.copyObject(
                CopyObjectArgs.builder()
                    .bucket(bucketName)
                    .object(targetObject)
                    .source(
                        CopySource.builder()
                            .bucket(bucketName)
                            .object(sourceObject)
                            .build()
                    )
                    .build()
            );
            log.info("æ–‡ä»¶å¤åˆ¶æˆåŠŸ: {} -> {}", sourceObject, targetObject);
        } catch (Exception e) {
            log.error("æ–‡ä»¶å¤åˆ¶å¤±è´¥", e);
            throw new StorageException("æ–‡ä»¶å¤åˆ¶å¤±è´¥", e);
        }
    }

    /**
     * åˆ—å‡ºæ–‡ä»¶
     */
    public List<Item> listFiles(String prefix) {
        try {
            Iterable<Result<Item>> results = minioClient.listObjects(
                ListObjectsArgs.builder()
                    .bucket(bucketName)
                    .prefix(prefix)
                    .recursive(true)
                    .build()
            );

            List<Item> items = new ArrayList<>();
            for (Result<Item> result : results) {
                items.add(result.get());
            }
            return items;
        } catch (Exception e) {
            log.error("åˆ—å‡ºæ–‡ä»¶å¤±è´¥", e);
            throw new StorageException("åˆ—å‡ºæ–‡ä»¶å¤±è´¥", e);
        }
    }
}
```

### 4. Storage é…ç½®

```java
/**
 * å­˜å‚¨é…ç½®
 */
@Configuration
public class StorageConfig {

    @Value("${minio.endpoint}")
    private String endpoint;

    @Value("${minio.access-key}")
    private String accessKey;

    @Value("${minio.secret-key}")
    private String secretKey;

    @Bean
    public MinioClient minioClient() {
        return MinioClient.builder()
            .endpoint(endpoint)
            .credentials(accessKey, secretKey)
            .build();
    }
}
```

### 5. Spring Boot é›†æˆ

```yaml
# application-storage.yml
minio:
  endpoint: http://minio.minio-storage:9000
  access-key: admin
  secret-key: password123
  bucket: basebackend-files

spring:
  servlet:
    multipart:
      max-file-size: 100MB
      max-request-size: 100MB
```

```java
/**
 * æ–‡ä»¶ä¸Šä¼ æ§åˆ¶å™¨
 */
@RestController
@RequestMapping("/api/storage")
@Api(tags = "æ–‡ä»¶å­˜å‚¨")
public class FileStorageController {

    @Autowired
    private MinioStorageService storageService;

    /**
     * ä¸Šä¼ æ–‡ä»¶
     */
    @PostMapping("/upload")
    @ApiOperation("ä¸Šä¼ æ–‡ä»¶")
    public Result<String> uploadFile(@RequestParam("file") MultipartFile file) {
        try {
            String objectName = generateObjectName(file.getOriginalFilename());
            storageService.uploadFile(
                objectName,
                file.getInputStream(),
                file.getContentType(),
                file.getSize()
            );

            // è¿”å›è®¿é—®URL
            String fileUrl = storageService.getFileUrl(objectName, 3600);
            return Result.success(fileUrl);
        } catch (Exception e) {
            log.error("æ–‡ä»¶ä¸Šä¼ å¤±è´¥", e);
            return Result.error("æ–‡ä»¶ä¸Šä¼ å¤±è´¥");
        }
    }

    /**
     * ä¸‹è½½æ–‡ä»¶
     */
    @GetMapping("/download/{objectName}")
    @ApiOperation("ä¸‹è½½æ–‡ä»¶")
    public ResponseEntity<Resource> downloadFile(@PathVariable String objectName) {
        try {
            InputStream is = storageService.downloadFile(objectName);
            HttpHeaders headers = new HttpHeaders();
            headers.add(HttpHeaders.CONTENT_DISPOSITION,
                "attachment; filename=" + objectName);

            return ResponseEntity.ok()
                .headers(headers)
                .body(new InputStreamResource(is));
        } catch (Exception e) {
            log.error("æ–‡ä»¶ä¸‹è½½å¤±è´¥", e);
            return ResponseEntity.notFound().build();
        }
    }

    /**
     * åˆ é™¤æ–‡ä»¶
     */
    @DeleteMapping("/{objectName}")
    @ApiOperation("åˆ é™¤æ–‡ä»¶")
    public Result<Void> deleteFile(@PathVariable String objectName) {
        try {
            storageService.deleteFile(objectName);
            return Result.success();
        } catch (Exception e) {
            log.error("æ–‡ä»¶åˆ é™¤å¤±è´¥", e);
            return Result.error("æ–‡ä»¶åˆ é™¤å¤±è´¥");
        }
    }

    private String generateObjectName(String originalFilename) {
        String timestamp = LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy/MM/dd"));
        String uuid = UUID.randomUUID().toString();
        String extension = originalFilename.substring(originalFilename.lastIndexOf("."));
        return String.format("%s/%s%s", timestamp, uuid, extension);
    }
}
```

---

## ğŸ—„ï¸ åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ (CephFS)

### 1. Ceph é›†ç¾¤éƒ¨ç½²

```yaml
# ceph-cluster.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: ceph-storage

---
# Ceph Monitors
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ceph-mon
  namespace: ceph-storage
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ceph-mon
  template:
    metadata:
      labels:
        app: ceph-mon
    spec:
      containers:
      - name: ceph-mon
        image: ceph/ceph:v17.2.5
        command: ["/bin/bash"]
        args:
          - -c
          - |
            ceph-mon --fsid=$FSID \
                     --mon.cluster=$CLUSTER_NAME \
                     --mon.interface=eth0 \
                     --mon.hostname=$(hostname) \
                     --public-addr=$PUBLIC_IP \
                     --setuser=ceph \
                     --setgroup=ceph \
                     --log-to-stderr=true \
                     --err-to-stderr=false \
                     --log-level=info \
                     --mon-data=$MON_DATA_DIR \
                     --mon.initial-members=$MON_INITIAL_MEMBERS
        env:
        - name: FSID
          value: "12345678-1234-1234-1234-123456789012"
        - name: CLUSTER_NAME
          value: "ceph-cluster"
        - name: PUBLIC_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: MON_DATA_DIR
          value: "/var/lib/ceph/mon/ceph-$(hostname)"
        - name: MON_INITIAL_MEMBERS
          value: "ceph-mon-0,ceph-mon-1,ceph-mon-2"
        volumeMounts:
        - name: mon-data
          mountPath: /var/lib/ceph/mon
        ports:
        - containerPort: 6789
          name: mon
      volumes:
      - name: mon-data
        persistentVolumeClaim:
          claimName: ceph-mon-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: ceph-mon-service
  namespace: ceph-storage
spec:
  clusterIP: None
  selector:
    app: ceph-mon
  ports:
  - port: 6789
    name: mon

---
# Ceph OSDs
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: ceph-osd
  namespace: ceph-storage
spec:
  selector:
    matchLabels:
      app: ceph-osd
  template:
    metadata:
      labels:
        app: ceph-osd
    spec:
      containers:
      - name: ceph-osd
        image: ceph/ceph:v17.2.5
        command: ["/bin/bash"]
        args:
          - -c
          - |
            ceph-osd --fsid=$FSID \
                     --setuser=ceph \
                     --setgroup=ceph \
                     --log-to-stderr=true \
                     --err-to-stderr=false \
                     --log-level=info \
                     --cluster=$CLUSTER_NAME \
                     --osd-data=$OSD_DATA_DIR \
                     --osd-journal=$OSD_JOURNAL_DIR \
                     --public-addr=$PUBLIC_IP
        env:
        - name: FSID
          value: "12345678-1234-1234-1234-123456789012"
        - name: CLUSTER_NAME
          value: "ceph-cluster"
        - name: PUBLIC_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: OSD_DATA_DIR
          value: "/var/lib/ceph/osd/ceph-$(hostname)"
        - name: OSD_JOURNAL_DIR
          value: "/var/lib/ceph/osd/journal"
        volumeMounts:
        - name: osd-data
          mountPath: /var/lib/ceph/osd
        - name: osd-journal
          mountPath: /var/lib/ceph/osd/journal
      volumes:
      - name: osd-data
        hostPath:
          path: /var/lib/ceph/osd
      - name: osd-journal
        hostPath:
          path: /var/lib/ceph/osd/journal
```

### 2. CephFS å®¢æˆ·ç«¯é…ç½®

```yaml
# cephfs-provisioner.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: cephfs-provisioner
  namespace: ceph-storage

---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: cephfs-provisioner
rules:
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["create", "get", "delete"]
- apiGroups: [""]
  resources: ["endpoints"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["list", "get"]
- apiGroups: [""]
  resources: ["namespaces"]
  verbs: ["list", "get"]
- apiGroups: [""]
  resources: ["persistentvolumes"]
  verbs: ["list", "get", "create", "delete"]
- apiGroups: [""]
  resources: ["persistentvolumeclaims"]
  verbs: ["list", "get", "update", "create"]

---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: cephfs-provisioner
subjects:
- kind: ServiceAccount
  name: cephfs-provisioner
  namespace: ceph-storage
roleRef:
  kind: ClusterRole
  name: cephfs-provisioner
  apiGroup: rbac.authorization.k8s.io/v1

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cephfs-provisioner
  namespace: ceph-storage
spec:
  selector:
    matchLabels:
      app: cephfs-provisioner
  replicas: 1
  template:
    metadata:
      labels:
        app: cephfs-provisioner
    spec:
      serviceAccountName: cephfs-provisioner
      containers:
      - name: provisioner
        image: ceph/cephfs-provisioner:latest
        env:
        - name: PROVISIONER_NAME
          value: "ceph.com/cephfs"
        - name: MONITOR_ENDPOINT
          value: "ceph-mon-service.ceph-storage:6789"
        - name: MONITOR_PATH
          value: "/ceph-mon-map"
        - name: MONITOR_USER
          value: "admin"
```

### 3. StorageClass é…ç½®

```yaml
# cephfs-storageclass.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: cephfs
  provisioner: ceph.com/cephfs
  parameters:
    monitors: "ceph-mon-service.ceph-storage:6789"
    adminId: admin
    adminSecretName: ceph-secret
    adminSecretNamespace: ceph-storage
    path: "/"
    fsType: ceph
    pool: cephfs_data
reclaimPolicy: Delete
allowVolumeExpansion: true
mountOptions:
  - debug
```

### 4. å®¢æˆ·ç«¯ä½¿ç”¨ç¤ºä¾‹

```java
/**
 * CephFS æ–‡ä»¶ç³»ç»Ÿå®¢æˆ·ç«¯
 */
@Component
public class CephFSClient {

    private Path cephFSPath;
    private FileSystem cephFS;

    @PostConstruct
    public void init() {
        try {
            // è¿æ¥åˆ° CephFS é›†ç¾¤
            String monitorAddress = "ceph-mon-service.ceph-storage:6789";
            Configuration conf = new Configuration();
            conf.set("fs.defaultFS", "hdfs://" + monitorAddress);

            cephFS = FileSystem.get(conf);
            cephFSPath = new Path("/basebackend-data");

            // ç¡®ä¿ç›®å½•å­˜åœ¨
            if (!cephFS.exists(cephFSPath)) {
                cephFS.mkdirs(cephFSPath);
            }
        } catch (Exception e) {
            log.error("CephFS åˆå§‹åŒ–å¤±è´¥", e);
        }
    }

    /**
     * ä¸Šä¼ æ–‡ä»¶åˆ° CephFS
     */
    public void uploadToCephFS(String localFilePath, String remoteFilePath) {
        try {
            Path remotePath = new Path(cephFSPath, remoteFilePath);
            Path localPath = Paths.get(localFilePath);

            cephFS.copyFromLocalFile(localPath, remotePath);
            log.info("æ–‡ä»¶ä¸Šä¼ åˆ° CephFS: {}", remoteFilePath);
        } catch (Exception e) {
            log.error("æ–‡ä»¶ä¸Šä¼ å¤±è´¥", e);
            throw new StorageException("CephFS æ–‡ä»¶ä¸Šä¼ å¤±è´¥", e);
        }
    }

    /**
     * ä» CephFS ä¸‹è½½æ–‡ä»¶
     */
    public void downloadFromCephFS(String remoteFilePath, String localFilePath) {
        try {
            Path remotePath = new Path(cephFSPath, remoteFilePath);
            Path localPath = Paths.get(localFilePath);

            // ç¡®ä¿æœ¬åœ°ç›®å½•å­˜åœ¨
            Files.createDirectories(localPath.getParent());

            cephFS.copyToLocalFile(remotePath, localPath);
            log.info("æ–‡ä»¶ä» CephFS ä¸‹è½½: {}", remoteFilePath);
        } catch (Exception e) {
            log.error("æ–‡ä»¶ä¸‹è½½å¤±è´¥", e);
            throw new StorageException("CephFS æ–‡ä»¶ä¸‹è½½å¤±è´¥", e);
        }
    }

    /**
     * åˆ é™¤ CephFS ä¸Šçš„æ–‡ä»¶
     */
    public void deleteFromCephFS(String remoteFilePath) {
        try {
            Path remotePath = new Path(cephFSPath, remoteFilePath);
            cephFS.delete(remotePath, true);
            log.info("æ–‡ä»¶ä» CephFS åˆ é™¤: {}", remoteFilePath);
        } catch (Exception e) {
            log.error("æ–‡ä»¶åˆ é™¤å¤±è´¥", e);
            throw new StorageException("CephFS æ–‡ä»¶åˆ é™¤å¤±è´¥", e);
        }
    }

    /**
     * åˆ—å‡º CephFS ä¸Šçš„æ–‡ä»¶
     */
    public FileStatus[] listFiles(String remoteDir) {
        try {
            Path remotePath = new Path(cephFSPath, remoteDir);
            return cephFS.listStatus(remotePath);
        } catch (Exception e) {
            log.error("åˆ—å‡ºæ–‡ä»¶å¤±è´¥", e);
            throw new StorageException("CephFS åˆ—å‡ºæ–‡ä»¶å¤±è´¥", e);
        }
    }

    @PreDestroy
    public void cleanup() {
        if (cephFS != null) {
            try {
                cephFS.close();
            } catch (Exception e) {
                log.error("å…³é—­ CephFS è¿æ¥å¤±è´¥", e);
            }
        }
    }
}
```

---

## ğŸ’¾ æ•°æ®åº“äº‘åŒ–

### 1. RDS MySQL ä¸»ä»é…ç½®

```yaml
# mysql-rds.yaml
apiVersion: v1
kind: Secret
metadata:
  name: mysql-secret
type: Opaque
data:
  password: cGFzc3dvcmQxMjM=  # base64ç¼–ç çš„å¯†ç 

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: mysql-config
data:
  master.cnf: |
    [mysqld]
    server-id = 1
    log-bin = mysql-bin
    binlog-format = ROW
    sync_binlog = 1
    innodb_flush_log_at_trx_commit = 1
    max_connections = 2000

  slave.cnf: |
    [mysqld]
    server-id = 2
    read_only = 1
    relay_log = mysql-relay-log
    log-slave-updates = 1
    max_connections = 2000

---
# MySQL ä¸»åº“
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql-master
  labels:
    app: mysql
    role: master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mysql
      role: master
  template:
    metadata:
      labels:
        app: mysql
        role: master
    spec:
      containers:
      - name: mysql
        image: mysql:8.0
        ports:
        - containerPort: 3306
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: password
        volumeMounts:
        - name: mysql-config
          mountPath: /etc/mysql/conf.d/
        - name: mysql-data
          mountPath: /var/lib/mysql
        resources:
          limits:
            memory: 4Gi
            cpu: 2000m
          requests:
            memory: 2Gi
            cpu: 1000m
      volumes:
      - name: mysql-config
        configMap:
          name: mysql-config
      - name: mysql-data
        persistentVolumeClaim:
          claimName: mysql-master-pvc

---
# MySQL ä»åº“
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql-slave
  labels:
    app: mysql
    role: slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: mysql
      role: slave
  template:
    metadata:
      labels:
        app: mysql
        role: slave
    spec:
      containers:
      - name: mysql
        image: mysql:8.0
        ports:
        - containerPort: 3306
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: password
        volumeMounts:
        - name: mysql-config
          mountPath: /etc/mysql/conf.d/
        - name: mysql-data
          mountPath: /var/lib/mysql
        resources:
          limits:
            memory: 4Gi
            cpu: 2000m
          requests:
            memory: 2Gi
            cpu: 1000m
      volumes:
      - name: mysql-config
        configMap:
          name: mysql-config
      - name: mysql-data
        persistentVolumeClaim:
          claimName: mysql-slave-pvc

---
# MySQL æœåŠ¡
apiVersion: v1
kind: Service
metadata:
  name: mysql-master
  labels:
    app: mysql
    role: master
spec:
  type: ClusterIP
  ports:
  - port: 3306
    targetPort: 3306
  selector:
    app: mysql
    role: master

---
apiVersion: v1
kind: Service
metadata:
  name: mysql-slave
  labels:
    app: mysql
    role: slave
spec:
  type: LoadBalancer
  ports:
  - port: 3306
    targetPort: 3306
  selector:
    app: mysql
    role: slave

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-master-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
  storageClassName: fast-ssd

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-slave-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
  storageClassName: fast-ssd
```

### 2. æ•°æ®åº“ä¸»ä»å¤åˆ¶è„šæœ¬

```bash
#!/bin/bash
# setup-mysql-replication.sh

# åœ¨ä¸»åº“ä¸Šåˆ›å»ºå¤åˆ¶ç”¨æˆ·
mysql -u root -p'password' << EOF
CREATE USER 'replicator'@'%' IDENTIFIED BY 'replicator_password';
GRANT REPLICATION SLAVE ON *.* TO 'replicator'@'%';
FLUSH PRIVILEGES;
SHOW MASTER STATUS;
EOF

# åœ¨ä»åº“ä¸Šé…ç½®å¤åˆ¶
mysql -u root -p'password' << EOF
STOP SLAVE;
CHANGE MASTER TO
    MASTER_HOST='mysql-master',
    MASTER_USER='replicator',
    MASTER_PASSWORD='replicator_password',
    MASTER_LOG_FILE='mysql-bin.000001',
    MASTER_LOG_POS=154;
START SLAVE;
SHOW SLAVE STATUS\G;
EOF

echo "MySQL ä¸»ä»å¤åˆ¶é…ç½®å®Œæˆ!"
```

### 3. PostgreSQL é«˜å¯ç”¨é…ç½®

```yaml
# postgresql-ha.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgresql-config
data:
  postgresql.conf: |
    listen_addresses = '*'
    port = 5432
    max_connections = 200
    shared_buffers = 256MB
    effective_cache_size = 1GB
    work_mem = 4MB
    maintenance_work_mem = 64MB
    wal_level = replica
    max_wal_senders = 3
    wal_keep_size = 16
    hot_standby = on
    hot_standby_feedback = on

  pg_hba.conf: |
    host all all 0.0.0.0/0 md5
    host replication all 0.0.0.0/0 md5

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgresql
spec:
  serviceName: postgresql
  replicas: 3
  selector:
    matchLabels:
      app: postgresql
  template:
    metadata:
      labels:
        app: postgresql
    spec:
      containers:
      - name: postgresql
        image: postgres:15
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgresql-secret
              key: password
        - name: POSTGRES_DB
          value: "basebackend"
        - name: POSTGRES_USER
          value: "postgres"
        volumeMounts:
        - name: postgresql-data
          mountPath: /var/lib/postgresql/data
        - name: postgresql-config
          mountPath: /etc/postgresql
        resources:
          limits:
            memory: 2Gi
            cpu: 1000m
          requests:
            memory: 1Gi
            cpu: 500m
      volumes:
      - name: postgresql-config
        configMap:
          name: postgresql-config
  volumeClaimTemplates:
  - metadata:
      name: postgresql-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 50Gi
      storageClassName: fast-ssd

---
apiVersion: v1
kind: Service
metadata:
  name: postgresql
spec:
  clusterIP: None
  selector:
    app: postgresql
  ports:
  - port: 5432
    targetPort: 5432

---
apiVersion: v1
kind: Service
metadata:
  name: postgresql-read
spec:
  selector:
    app: postgresql
  ports:
  - port: 5432
    targetPort: 5432
```

### 4. Redis é›†ç¾¤é…ç½®

```yaml
# redis-cluster.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-config
data:
  redis.conf: |
    bind 0.0.0.0
    port 6379
    protected-mode no
    cluster-enabled yes
    cluster-config-file nodes.conf
    cluster-node-timeout 5000
    cluster-announce-ip redis-cluster
    cluster-announce-port 6379
    cluster-announce-bus-port 16379
    appendonly yes
    maxmemory 1gb
    maxmemory-policy allkeys-lru

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis-cluster
spec:
  serviceName: redis-cluster
  replicas: 6
  selector:
    matchLabels:
      app: redis-cluster
  template:
    metadata:
      labels:
        app: redis-cluster
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
        - containerPort: 16379
        command:
        - redis-server
        - /etc/redis/redis.conf
        volumeMounts:
        - name: redis-config
          mountPath: /etc/redis
        - name: redis-data
          mountPath: /data
        resources:
          limits:
            memory: 2Gi
            cpu: 1000m
          requests:
            memory: 1Gi
            cpu: 500m
      volumes:
      - name: redis-config
        configMap:
          name: redis-config
  volumeClaimTemplates:
  - metadata:
      name: redis-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 10Gi
      storageClassName: fast-ssd

---
apiVersion: v1
kind: Service
metadata:
  name: redis-cluster
spec:
  clusterIP: None
  selector:
    app: redis-cluster
  ports:
  - port: 6379
    targetPort: 6379
  - port: 16379
    targetPort: 16379
```

### 5. æ•°æ®æºé…ç½®

```java
/**
 * äº‘æ•°æ®åº“æ•°æ®æºé…ç½®
 */
@Configuration
public class CloudDatabaseConfig {

    @Value("${cloud.database.type}")
    private String databaseType;

    @Value("${cloud.database.primary.url}")
    private String primaryUrl;

    @Value("${cloud.database.primary.username}")
    private String primaryUsername;

    @Value("${cloud.database.primary.password}")
    private String primaryPassword;

    @Value("${cloud.database.secondary.url}")
    private String secondaryUrl;

    @Value("${cloud.database.secondary.username}")
    private String secondaryUsername;

    @Value("${cloud.database.secondary.password}")
    private String secondaryPassword;

    /**
     * ä¸»æ•°æ®æº
     */
    @Bean
    @Primary
    @ConfigurationProperties("spring.datasource.primary")
    public DataSource primaryDataSource() {
        return DataSourceBuilder.create()
            .url(primaryUrl)
            .username(primaryUsername)
            .password(primaryPassword)
            .build();
    }

    /**
     * ä»æ•°æ®æº
     */
    @Bean
    @ConfigurationProperties("spring.datasource.secondary")
    public DataSource secondaryDataSource() {
        return DataSourceBuilder.create()
            .url(secondaryUrl)
            .username(secondaryUsername)
            .password(secondaryPassword)
            .build();
    }

    /**
     * åŠ¨æ€æ•°æ®æº
     */
    @Bean
    public DataSource dynamicDataSource() {
        DynamicDataSource dynamicDataSource = new DynamicDataSource();
        Map<Object, Object> dataSourceMap = new HashMap<>();
        dataSourceMap.put("primary", primaryDataSource());
        dataSourceMap.put("secondary", secondaryDataSource());
        dynamicDataSource.setTargetDataSources(dataSourceMap);
        dynamicDataSource.setDefaultTargetDataSource(primaryDataSource());
        return dynamicDataSource;
    }
}
```

---

## ğŸ“Š å¤‡ä»½ä¸æ¢å¤

### 1. å¤‡ä»½ç­–ç•¥è„šæœ¬

```bash
#!/bin/bash
# backup-strategy.sh

set -e

BACKUP_DIR="/backup"
S3_BUCKET="basebackend-backups"
DATE=$(date +%Y%m%d_%H%M%S)

# MySQL å¤‡ä»½
backup_mysql() {
    echo "å¼€å§‹å¤‡ä»½ MySQL æ•°æ®åº“..."

    # å…¨é‡å¤‡ä»½
    mysqldump --single-transaction --routines --triggers \
        --all-databases > $BACKUP_DIR/mysql_full_$DATE.sql

    # ä¸Šä¼ åˆ° S3
    aws s3 cp $BACKUP_DIR/mysql_full_$DATE.sql \
        s3://$S3_BUCKET/mysql/

    # æ¸…ç†æœ¬åœ°æ–‡ä»¶
    rm -f $BACKUP_DIR/mysql_full_*.sql

    echo "MySQL å¤‡ä»½å®Œæˆ"
}

# PostgreSQL å¤‡ä»½
backup_postgresql() {
    echo "å¼€å§‹å¤‡ä»½ PostgreSQL æ•°æ®åº“..."

    pg_basebackup -D $BACKUP_DIR/pg_backup_$DATE -Ft -z -P

    # ä¸Šä¼ åˆ° S3
    aws s3 cp $BACKUP_DIR/pg_backup_$DATE.tar.gz \
        s3://$S3_BUCKET/postgresql/

    # æ¸…ç†æœ¬åœ°æ–‡ä»¶
    rm -rf $BACKUP_DIR/pg_backup_*

    echo "PostgreSQL å¤‡ä»½å®Œæˆ"
}

# MinIO å¤‡ä»½
backup_minio() {
    echo "å¼€å§‹å¤‡ä»½ MinIO æ•°æ®..."

    # åˆ—å‡ºæ‰€æœ‰ bucket
    buckets=$(mc ls basebackend)

    for bucket in $buckets; do
        echo "å¤‡ä»½ bucket: $bucket"
        mc mirror basebackend/$bucket \
            s3/$S3_BUCKET/minio/$bucket/
    done

    echo "MinIO å¤‡ä»½å®Œæˆ"
}

# CephFS å¤‡ä»½
backup_cephfs() {
    echo "å¼€å§‹å¤‡ä»½ CephFS æ•°æ®..."

    # ä½¿ç”¨ rsync å¤‡ä»½æ•°æ®
    rsync -avz --progress \
        cephfs-mount/ \
        $BACKUP_DIR/cephfs_$DATE/

    # ä¸Šä¼ åˆ° S3
    tar -czf $BACKUP_DIR/cephfs_$DATE.tar.gz \
        $BACKUP_DIR/cephfs_$DATE/
    aws s3 cp $BACKUP_DIR/cephfs_$DATE.tar.gz \
        s3://$S3_BUCKET/cephfs/

    # æ¸…ç†æœ¬åœ°æ–‡ä»¶
    rm -rf $BACKUP_DIR/cephfs_*

    echo "CephFS å¤‡ä»½å®Œæˆ"
}

# æ‰§è¡Œæ‰€æœ‰å¤‡ä»½
backup_mysql
backup_postgresql
backup_minio
backup_cephfs

# è®¾ç½®ç”Ÿå‘½å‘¨æœŸç­–ç•¥ï¼ˆ7å¤©åè½¬å†·å­˜å‚¨ï¼Œ30å¤©ååˆ é™¤ï¼‰
aws s3api put-bucket-lifecycle-configuration \
    --bucket $S3_BUCKET \
    --lifecycle-configuration file://lifecycle-policy.json

echo "æ‰€æœ‰å¤‡ä»½ä»»åŠ¡å®Œæˆ!"
```

### 2. æ¢å¤è„šæœ¬

```bash
#!/bin/bash
# restore.sh

set -e

S3_BUCKET="basebackend-backups"
BACKUP_FILE="$1"

if [ -z "$BACKUP_FILE" ]; then
    echo "ç”¨æ³•: $0 <backup_file>"
    echo "ç¤ºä¾‹: $0 mysql_full_20241201_120000.sql"
    exit 1
fi

# ä» S3 ä¸‹è½½å¤‡ä»½æ–‡ä»¶
echo "ä¸‹è½½å¤‡ä»½æ–‡ä»¶: $BACKUP_FILE"
aws s3 cp s3://$S3_BUCKET/mysql/$BACKUP_FILE /tmp/

# æ¢å¤ MySQL æ•°æ®åº“
restore_mysql() {
    echo "æ¢å¤ MySQL æ•°æ®åº“..."
    mysql < /tmp/$BACKUP_FILE
    echo "MySQL æ•°æ®åº“æ¢å¤å®Œæˆ"
}

# é€‰æ‹©æ¢å¤é€‰é¡¹
echo "é€‰æ‹©æ¢å¤é€‰é¡¹:"
echo "1) MySQL"
echo "2) PostgreSQL"
read -p "è¯·é€‰æ‹© (1-2): " choice

case $choice in
    1)
        restore_mysql
        ;;
    2)
        echo "PostgreSQL æ¢å¤åŠŸèƒ½å¾…å®ç°"
        ;;
    *)
        echo "æ— æ•ˆé€‰æ‹©"
        exit 1
        ;;
esac

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
rm -f /tmp/$BACKUP_FILE

echo "æ•°æ®æ¢å¤å®Œæˆ!"
```

---

## ğŸ” ç›‘æ§ä¸å‘Šè­¦

### 1. å­˜å‚¨ç›‘æ§é…ç½®

```yaml
# storage-monitoring.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: storage-prometheus-rules
data:
  rules.yml: |
    groups:
    - name: storage.rules
      rules:
      # ç£ç›˜ä½¿ç”¨ç‡å‘Šè­¦
      - alert: DiskUsageHigh
        expr: (node_filesystem_size_bytes - node_filesystem_avail_bytes) / node_filesystem_size_bytes * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "{{ $labels.instance }} ç£ç›˜ä½¿ç”¨ç‡ä¸º {{ $value }}%"

      # MySQL è¿æ¥æ•°å‘Šè­¦
      - alert: MySQLConnectionsHigh
        expr: mysql_global_status_threads_connected / mysql_global_variables_max_connections * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "MySQL è¿æ¥æ•°è¿‡é«˜"
          description: "MySQL å½“å‰è¿æ¥æ•°: {{ $value }}%"

      # Redis å†…å­˜ä½¿ç”¨ç‡å‘Šè­¦
      - alert: RedisMemoryHigh
        expr: redis_memory_used_bytes / redis_memory_max_bytes * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Redis å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "Redis å†…å­˜ä½¿ç”¨ç‡: {{ $value }}%"

      # PostgreSQL æ…¢æŸ¥è¯¢å‘Šè­¦
      - alert: PostgreSQLSlowQueries
        expr: pg_stat_database_blks_hit / (pg_stat_database_blks_hit + pg_stat_database_blks_read) * 100 < 99
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "PostgreSQL ç¼“å­˜å‘½ä¸­ç‡ä½"
          description: "PostgreSQL ç¼“å­˜å‘½ä¸­ç‡: {{ $value }}%"

      # Ceph é›†ç¾¤å¥åº·çŠ¶æ€å‘Šè­¦
      - alert: CephHealthError
        expr: ceph_health_status == 2
        for: 0m
        labels:
          severity: critical
        annotations:
          summary: "Ceph é›†ç¾¤å¥åº·çŠ¶æ€å¼‚å¸¸"
          description: "Ceph é›†ç¾¤å½“å‰å¤„äºé”™è¯¯çŠ¶æ€"
```

### 2. Grafana ä»ªè¡¨ç›˜

```json
{
  "dashboard": {
    "title": "å­˜å‚¨ç›‘æ§ä»ªè¡¨ç›˜",
    "panels": [
      {
        "title": "ç£ç›˜ä½¿ç”¨æƒ…å†µ",
        "type": "graph",
        "targets": [
          {
            "expr": "node_filesystem_size_bytes - node_filesystem_avail_bytes",
            "legendFormat": "{{ instance }} - {{ mountpoint }}"
          }
        ]
      },
      {
        "title": "MySQL è¿æ¥æ•°",
        "type": "singlestat",
        "targets": [
          {
            "expr": "mysql_global_status_threads_connected",
            "legendFormat": "å½“å‰è¿æ¥æ•°"
          }
        ]
      },
      {
        "title": "Redis å†…å­˜ä½¿ç”¨",
        "type": "graph",
        "targets": [
          {
            "expr": "redis_memory_used_bytes",
            "legendFormat": "{{ instance }}"
          }
        ]
      },
      {
        "title": "PostgreSQL æŸ¥è¯¢æ€§èƒ½",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(pg_stat_database_tup_fetched[5m])",
            "legendFormat": "{{ instance }} - {{ datname }}"
          }
        ]
      }
    ]
  }
}
```

---

## ğŸ§ª æµ‹è¯•ä¸éªŒè¯

### 1. å­˜å‚¨æ€§èƒ½æµ‹è¯•è„šæœ¬

```bash
#!/bin/bash
# storage-performance-test.sh

set -e

# æµ‹è¯• MinIO æ€§èƒ½
test_minio_performance() {
    echo "æµ‹è¯• MinIO æ€§èƒ½..."

    # æµ‹è¯•å†™å…¥æ€§èƒ½
    dd if=/dev/zero of=/tmp/test_file bs=1M count=100
    time mc cp /tmp/test_file basebackend/test/performance.txt

    # æµ‹è¯•è¯»å–æ€§èƒ½
    time mc cp basebackend/test/performance.txt /tmp/download_test_file

    # æ¸…ç†æµ‹è¯•æ–‡ä»¶
    mc rm basebackend/test/performance.txt
    rm -f /tmp/test_file /tmp/download_test_file

    echo "MinIO æ€§èƒ½æµ‹è¯•å®Œæˆ"
}

# æµ‹è¯• MySQL æ€§èƒ½
test_mysql_performance() {
    echo "æµ‹è¯• MySQL æ€§èƒ½..."

    # åˆ›å»ºæµ‹è¯•è¡¨
    mysql -u root -p'password' << EOF
    CREATE DATABASE IF NOT EXISTS test_db;
    USE test_db;
    CREATE TABLE IF NOT EXISTS performance_test (
        id INT AUTO_INCREMENT PRIMARY KEY,
        data VARCHAR(255),
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );
EOF

    # æ‰¹é‡æ’å…¥æµ‹è¯•
    start_time=$(date +%s)
    for i in {1..1000}; do
        mysql -u root -p'password' test_db \
            "INSERT INTO performance_test (data) VALUES ('test data $i');"
    done
    end_time=$(date +%s)
    insert_time=$((end_time - start_time))

    # æŸ¥è¯¢æ€§èƒ½æµ‹è¯•
    start_time=$(date +%s)
    mysql -u root -p'password' test_db \
        "SELECT COUNT(*) FROM performance_test;" > /dev/null
    end_time=$(date +%s)
    query_time=$((end_time - start_time))

    echo "MySQL æ‰¹é‡æ’å…¥æ—¶é—´: ${insert_time}s"
    echo "MySQL æŸ¥è¯¢æ—¶é—´: ${query_time}s"

    # æ¸…ç†æµ‹è¯•æ•°æ®
    mysql -u root -p'password' test_db "DROP TABLE IF EXISTS performance_test;"

    echo "MySQL æ€§èƒ½æµ‹è¯•å®Œæˆ"
}

# æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
test_minio_performance
test_mysql_performance

echo "å­˜å‚¨æ€§èƒ½æµ‹è¯•å…¨éƒ¨å®Œæˆ!"
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

1. [MinIO å®˜æ–¹æ–‡æ¡£](https://min.io/docs/)
2. [Ceph å®˜æ–¹æ–‡æ¡£](https://docs.ceph.com/)
3. [Kubernetes å­˜å‚¨æ–‡æ¡£](https://kubernetes.io/docs/concepts/storage/)
4. [AWS RDS æœ€ä½³å®è·µ](https://aws.amazon.com/rds/)

---

**ç¼–åˆ¶ï¼š** æµ®æµ®é…± ğŸ±ï¼ˆçŒ«å¨˜å·¥ç¨‹å¸ˆï¼‰
**æ—¥æœŸï¼š** 2025-11-14
**çŠ¶æ€ï¼š** ğŸ“‹ æŒ‡å—å®Œæˆï¼Œå‡†å¤‡å®æ–½

**åŠ æ²¹å–µï½ äº‘åŸç”Ÿå­˜å‚¨å³å°†å®Œæˆï¼** à¸…'Ï‰'à¸…
